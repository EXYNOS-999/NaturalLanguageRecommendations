{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Santosh-Gupta/NaturalLanguageRecommendations/blob/srihari-dev/notebooks/model_debug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QK0_IOe0LkEY"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers cloud-tpu-client torch\n",
    "# !wget 'https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar'\n",
    "# !tar -xvf 'scibert_scivocab_uncased.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S_hHnz5fLiZ5",
    "outputId": "35daa83e-555f-48db-871a-c1b0098c3516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.1.0-dev20191226\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Lambda, Dense, Activation, Concatenate, Dropout\n",
    "from transformers import TFBertModel\n",
    "from time import time\n",
    "print('TensorFlow:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-1Mu1rsDMHCF",
    "outputId": "d604ad71-9e00-433f-b6db-bb2e2119bfb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  ['192.168.19.2:8470']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: srihari-1-tpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: srihari-1-tpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver('srihari-1-tpu')  # TPU detection\n",
    "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYscLlW_7wIR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 256\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 * strategy.num_replicas_in_sync\n",
    "embedding_dim = 512\n",
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_steps = 1262996 * 0.8 // batch_size\n",
    "val_steps = train_steps // 10\n",
    "epochs = 100\n",
    "print('Batch Size:', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEohYPP7QAK1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in:  gs://tfworld/model_files_2/logs_1577426847.0237095\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'gs://tfworld'\n",
    "model_dir = os.path.join(base_dir, 'model_files_2')\n",
    "tensorboard_dir = os.path.join(model_dir, 'logs_'+str(time()))\n",
    "tfrecords_pattern_train = os.path.join(base_dir, 'tfrecords', 'train*')\n",
    "tfrecords_pattern_val = os.path.join(base_dir, 'tfrecords', 'eval*')\n",
    "\n",
    "print('Logging in: ', tensorboard_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYONEmj6LiZ9"
   },
   "outputs": [],
   "source": [
    "features = {\n",
    "    'title':tf.io.FixedLenFeature([512], dtype=tf.int64),\n",
    "    'citation':tf.io.FixedLenFeature([512], dtype=tf.float32),\n",
    "    }\n",
    "\n",
    "def parse_example(example_proto):\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, features)\n",
    "    title = parsed_example['title']\n",
    "    citation = parsed_example['citation']\n",
    "    \n",
    "    title = tf.cast(title, dtype=tf.int32)\n",
    "    citation = tf.cast(citation, dtype=tf.float32)\n",
    "    return (title, citation), tf.constant([1.0], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Sg8AtlNpQAK7",
    "outputId": "49122387-74be-4cbc-8d1b-244a6f8bfff0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((TensorSpec(shape=(256, 512), dtype=tf.int32, name=None),\n",
       "   TensorSpec(shape=(256, 512), dtype=tf.float32, name=None)),\n",
       "  TensorSpec(shape=(256, 1), dtype=tf.float32, name=None)),\n",
       " ((TensorSpec(shape=(256, 512), dtype=tf.int32, name=None),\n",
       "   TensorSpec(shape=(256, 512), dtype=tf.float32, name=None)),\n",
       "  TensorSpec(shape=(256, 1), dtype=tf.float32, name=None)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    train_files = tf.data.Dataset.list_files(tfrecords_pattern_train)\n",
    "    train_dataset = train_files.interleave(tf.data.TFRecordDataset,\n",
    "                                           cycle_length=32,\n",
    "                                           block_length=4,\n",
    "                                           num_parallel_calls=autotune)\n",
    "    train_dataset = train_dataset.map(parse_example, num_parallel_calls=autotune)\n",
    "    train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "    train_dataset = train_dataset.repeat()\n",
    "    train_dataset = train_dataset.prefetch(autotune)\n",
    "\n",
    "    val_files = tf.data.Dataset.list_files(tfrecords_pattern_val)\n",
    "    val_dataset = val_files.interleave(tf.data.TFRecordDataset,\n",
    "                                       cycle_length=32,\n",
    "                                       block_length=4,\n",
    "                                       num_parallel_calls=autotune)\n",
    "    val_dataset = val_dataset.map(parse_example, num_parallel_calls=autotune)\n",
    "    val_dataset = val_dataset.batch(batch_size, drop_remainder=True)\n",
    "    val_dataset = val_dataset.repeat()\n",
    "    val_dataset = val_dataset.prefetch(autotune)\n",
    "\n",
    "tf.data.experimental.get_structure(train_dataset), tf.data.experimental.get_structure(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TidDJ55-LiZ_"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss_fn(_, probs):\n",
    "    '''\n",
    "        1. Every sample is its own positive, and  the rest of the\n",
    "            elements in the batch are its negative.\n",
    "        2. Each TPU core gets 1/8 * global_batch_size elements, hence\n",
    "            compute shape dynamically.\n",
    "        3. Dataset produces dummy labels to make sure the loss_fn matches\n",
    "            the loss signature of keras, actual labels are computed inside this\n",
    "            function.\n",
    "        4. `probs` lie in [0, 1] and are to be treated as probabilities.\n",
    "    '''\n",
    "    bs = tf.shape(probs)[0] \n",
    "    labels = tf.eye(bs, bs)\n",
    "    return tf.losses.categorical_crossentropy(labels, probs, from_logits=False)\n",
    "    \n",
    "def create_model(drop_out):\n",
    "    textIds = tf.keras.Input(shape=(512,), dtype=tf.int32)    # from bert tokenizer\n",
    "    citation = tf.keras.Input(shape=(512,))                   # normalized word2vec outputs\n",
    "    \n",
    "    bert_model = TFBertModel.from_pretrained('scibert_scivocab_uncased', from_pt=True)\n",
    "    \n",
    "    textOut = bert_model(textIds)\n",
    "    textOutMean = tf.reduce_mean(textOut[0], axis=1)\n",
    "    textOutSim = Dense(units=embedding_dim, activation='tanh', name='DenseTitle')(textOutMean)\n",
    "    textOutSim = Dropout(drop_out)(textOutSim)\n",
    "    \n",
    "    citationSim = Dense(units=embedding_dim, activation='tanh', name='DenseCitation')(citation)\n",
    "    citationSim = Dropout(drop_out)(citationSim)\n",
    "\n",
    "    # Get dot product of each of title x citation combinations\n",
    "    dotProduct = tf.reduce_sum(tf.multiply(textOutSim[:, None, :], citationSim), axis=-1)\n",
    "    \n",
    "    # Softmax to make sure each row has sum == 1.0\n",
    "    probs = tf.nn.softmax(dotProduct, axis=-1)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[textIds, citation], outputs=[probs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8MXgYFSLiaB"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model(drop_out=0.20)\n",
    "    model.compile(loss=loss_fn,\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3f-F4QXDmL7"
   },
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir=tensorboard_dir, update_freq='epoch'), \n",
    "            tf.keras.callbacks.ModelCheckpoint(filepath=model_dir + '/epoch_{epoch:02d}_{loss:.2f}',\n",
    "                                               monitor='loss',\n",
    "                                               verbose=1,\n",
    "                                               save_weights_only=True,\n",
    "                                               save_freq='epoch')\n",
    "                                               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "p6S3kWXPLiaF",
    "outputId": "576ab892-4002-4424-b9d1-d13055c40b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 3946.0 steps, validate for 394.0 steps\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/3946 [..............................] - ETA: 74:42:48 - loss: 3.7574WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.095701). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.095701). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3945/3946 [============================>.] - ETA: 0s - loss: 3.0831\n",
      "Epoch 00001: saving model to gs://tfworld/model_files_2/epoch_01_3.08\n",
      "3946/3946 [==============================] - 2403s 609ms/step - loss: 3.0830 - val_loss: 2.7980\n",
      "Epoch 2/100\n",
      "3945/3946 [============================>.] - ETA: 0s - loss: 2.7259\n",
      "Epoch 00002: saving model to gs://tfworld/model_files_2/epoch_02_2.73\n",
      "3946/3946 [==============================] - 2362s 599ms/step - loss: 2.7259 - val_loss: 2.5801\n",
      "Epoch 3/100\n",
      "3945/3946 [============================>.] - ETA: 0s - loss: 2.4969\n",
      "Epoch 00003: saving model to gs://tfworld/model_files_2/epoch_03_2.50\n",
      "3946/3946 [==============================] - 2363s 599ms/step - loss: 2.4969 - val_loss: 2.4444\n",
      "Epoch 4/100\n",
      "3945/3946 [============================>.] - ETA: 0s - loss: 2.3048\n",
      "Epoch 00004: saving model to gs://tfworld/model_files_2/epoch_04_2.30\n",
      "3946/3946 [==============================] - 2359s 598ms/step - loss: 2.3047 - val_loss: 2.3618\n",
      "Epoch 5/100\n",
      "3945/3946 [============================>.] - ETA: 0s - loss: 2.1282\n",
      "Epoch 00005: saving model to gs://tfworld/model_files_2/epoch_05_2.13\n",
      "3946/3946 [==============================] - 2362s 599ms/step - loss: 2.1281 - val_loss: 2.3036\n",
      "Epoch 6/100\n",
      "3945/3946 [============================>.] - ETA: 0s - loss: 1.9581\n",
      "Epoch 00006: saving model to gs://tfworld/model_files_2/epoch_06_1.96\n",
      "3946/3946 [==============================] - 2382s 604ms/step - loss: 1.9580 - val_loss: 2.2698\n",
      "Epoch 7/100\n",
      "3945/3946 [============================>.] - ETA: 0s - loss: 1.7960"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset,\n",
    "          epochs=epochs,\n",
    "          steps_per_epoch=train_steps,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=val_steps,\n",
    "          validation_freq=1,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B8DkqlzfDmL_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "model_debug.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
