{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "build_index_and_search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santosh-Gupta/NaturalLanguageRecommendations/blob/master/notebooks/inference/build_index_and_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8wAw2JV6F4Am",
        "outputId": "7c99e554-ea52-4bb5-97cd-a46d222df315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "!gdown --id \"10LV9QbZOkUyOzR4nh8hxesoKJhpmvpM9\"   # citation vectors\n",
        "!gdown --id \"1-23aNm7j0bnycvyd_OaQfofVYPTewgOI\"   # abstract vectors\n",
        "!gdown --id \"1NyUQwgUNj9bFsiCnZ2TfKmWn5r-Y6wav\"   # TitlesIdAbstractsEmbedIds\n",
        "!wget 'https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar'\n",
        "!tar -xvf 'scibert_scivocab_uncased.tar'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10LV9QbZOkUyOzR4nh8hxesoKJhpmvpM9\n",
            "To: /content/CitationSimilarityVectors106Epochs.npy\n",
            "2.59GB [00:41, 63.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-23aNm7j0bnycvyd_OaQfofVYPTewgOI\n",
            "To: /content/AbstractSimVectors.npy\n",
            "2.59GB [00:40, 63.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NyUQwgUNj9bFsiCnZ2TfKmWn5r-Y6wav\n",
            "To: /content/TitlesIdsAbstractsEmbedIdsCOMPLETE_12-30-19.json.gzip\n",
            "432MB [00:07, 58.8MB/s]\n",
            "--2019-12-31 07:48:42--  https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar\n",
            "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.192.112\n",
            "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.192.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 442460160 (422M) [application/x-tar]\n",
            "Saving to: ‘scibert_scivocab_uncased.tar’\n",
            "\n",
            "scibert_scivocab_un 100%[===================>] 421.96M  48.5MB/s    in 9.1s    \n",
            "\n",
            "2019-12-31 07:48:52 (46.6 MB/s) - ‘scibert_scivocab_uncased.tar’ saved [442460160/442460160]\n",
            "\n",
            "scibert_scivocab_uncased/\n",
            "scibert_scivocab_uncased/vocab.txt\n",
            "scibert_scivocab_uncased/pytorch_model.bin\n",
            "scibert_scivocab_uncased/config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP2AqdEiQhbS",
        "colab_type": "code",
        "outputId": "2919f459-7574-4be4-9642-39f60c184b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install transformers --quiet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 450kB 3.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 58.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 860kB 52.3MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SGov6e8uGO3B",
        "outputId": "89a82d1b-2a9a-4596-8580-57ded8f9ca62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "print('TensorFlow:', tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "TensorFlow: 2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iht3WQa3H_g6",
        "outputId": "afbe2cc3-a6cd-46af-a215-b2eb8b8b258d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.55.148.58:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: 10.55.148.58:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.55.148.58:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ks95sxuIKbR",
        "outputId": "9f1c5212-0282-4f49-8f39-cc88f4a2365e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "if tpu:\n",
        "  workers = ['/job:worker/replica:0/task:0/device:TPU:'+str(i) for i in range(8)]\n",
        "  print(workers)\n",
        "  gpu =''\n",
        "if tf.config.experimental.list_physical_devices('GPU'):\n",
        "  gpu = 'gpu'\n",
        "  workers = ['/GPU:0']\n",
        "  print(workers)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/job:worker/replica:0/task:0/device:TPU:0', '/job:worker/replica:0/task:0/device:TPU:1', '/job:worker/replica:0/task:0/device:TPU:2', '/job:worker/replica:0/task:0/device:TPU:3', '/job:worker/replica:0/task:0/device:TPU:4', '/job:worker/replica:0/task:0/device:TPU:5', '/job:worker/replica:0/task:0/device:TPU:6', '/job:worker/replica:0/task:0/device:TPU:7']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uByeXRrVO78_",
        "colab": {}
      },
      "source": [
        "class Index:\n",
        "    def __init__(self, embeddings, worker):\n",
        "        self.embeddings = tf.math.l2_normalize(embeddings, axis=1)\n",
        "        self.worker = worker\n",
        "\n",
        "    @tf.function\n",
        "    def search(self, query_vector):\n",
        "      with tf.device(worker):\n",
        "        dot_product = tf.reduce_sum(tf.multiply(self.embeddings, query_vector), axis=1)\n",
        "        distances = 1 - dot_product\n",
        "        sorted_indices =  tf.argsort(distances)\n",
        "        nearest_distances = tf.gather(distances, sorted_indices)\n",
        "        return nearest_distances[:20], sorted_indices[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DFloyWt7G8ts",
        "colab": {}
      },
      "source": [
        "citations_embeddings = np.load('CitationSimilarityVectors106Epochs.npy')\n",
        "abstract_embeddings = np.load('AbstractSimVectors.npy')\n",
        "assert citations_embeddings.shape == abstract_embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AB8L4sA-H2nf",
        "outputId": "efca2670-4b17-430f-d0ae-b84f87b248a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if tpu:\n",
        "  # Discarding last 4 vectors to make number of vectors divisible by 8\n",
        "  citations_embeddings = np.split(citations_embeddings[:-4], 8, axis=0)\n",
        "  abstract_embeddings = np.split(abstract_embeddings[:-4], 8, axis=0)\n",
        "  vecs_per_index = citations_embeddings[0].shape[0]\n",
        "  print('Vectors per index :', vecs_per_index)\n",
        "elif gpu:\n",
        "  vecs_per_index = citations_embeddings.shape[0]\n",
        "  print('Vectors per index :', vecs_per_index)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectors per index : 157874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HoEA0SqeJW4n",
        "outputId": "4aa84f16-a9be-4887-f645-3dc3ba8a8a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "citation_indices = []\n",
        "abstract_indices = []\n",
        "if gpu:\n",
        "  for i, worker in enumerate(workers):\n",
        "    with tf.device(worker):\n",
        "      print('Building index with {} vectors on {}'.format(citations_embeddings.shape[0], worker))\n",
        "      citation_indices.append(Index(citations_embeddings, worker))\n",
        "      abstract_indices.append(Index(abstract_embeddings, worker))\n",
        "elif tpu:\n",
        "  ## Place 1/8 of total embeddings on each TPU core\n",
        "  for i, worker in enumerate(workers):\n",
        "    with tf.device(worker):\n",
        "      print('Building index with {} vectors on {}'.format(citations_embeddings[i].shape[0],worker))\n",
        "      citation_indices.append(Index(citations_embeddings[i], worker))\n",
        "      abstract_indices.append(Index(abstract_embeddings[i], worker))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:0\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:1\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:2\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:3\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:4\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:5\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:6\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W5r4LmcVqGAZ",
        "colab": {}
      },
      "source": [
        "def search(xq, top_k=10):\n",
        "  cD, cI = [], []\n",
        "  aD, aI = [], []\n",
        "  if tpu:\n",
        "    r = 8\n",
        "  else:\n",
        "    r = 1\n",
        "  for i in range(r):\n",
        "    print('Search running on {}'.format(citation_indices[i].worker))\n",
        "    cd, cidx = citation_indices[i].search(xq)\n",
        "    ad, aidx = abstract_indices[i].search(xq)\n",
        "\n",
        "    cD.extend(cd.numpy())\n",
        "    aD.extend(ad.numpy())\n",
        "\n",
        "    cI.extend(i*vecs_per_index + cidx.numpy())\n",
        "    aI.extend(i*vecs_per_index + aidx.numpy())\n",
        "\n",
        "  cid_sorted = np.argsort(cD)[:top_k]\n",
        "  aid_sorted = np.argsort(aD)[:top_k]\n",
        "\n",
        "  cD = np.array(cD)[cid_sorted]\n",
        "  aD = np.array(aD)[aid_sorted]\n",
        "\n",
        "  cI = np.array(cI)[cid_sorted]\n",
        "  aI = np.array(aI)[aid_sorted]\n",
        "  return cD, aD, cI, aI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syc0k8Yi4rcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.saved_model.load('gs://tfworld/saved_models')\n",
        "tokenizer = BertTokenizer(vocab_file='scibert_scivocab_uncased/vocab.txt')\n",
        "\n",
        "df = pd.read_json('/content/TitlesIdsAbstractsEmbedIdsCOMPLETE_12-30-19.json.gzip', compression = 'gzip')\n",
        "embed2Title = pd.Series(df['title'].values,index=df['EmbeddingID']).to_dict()\n",
        "embed2Abstract = pd.Series(df['paperAbstract'].values,index=df['EmbeddingID']).to_dict()\n",
        "embed2Paper = pd.Series(df['id'].values,index=df['EmbeddingID']).to_dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxkcuP0CDNKM",
        "colab_type": "code",
        "outputId": "ad9f2fc5-dea1-42e8-ba2a-983f0451dcae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# embed_id = 70000\n",
        "# title = embed2Title[embed_id]\n",
        "title = 'Title'\n",
        "#abstract = embed2Abstract[embed_id]\n",
        "abstract = '''Forecasting stock market direction is always an amazing but challenging problem in finance. Although many popular shallow computational methods (such as Backpropagation Network and Support Vector Machine) have extensively been proposed, most algorithms have not yet attained a desirable level of applicability. In this paper, we present a deep learning model with strong ability to generate high level feature representations for accurate financial prediction. Precisely, a stacked denoising autoencoder (SDAE) from deep learning is applied to predict the daily CSI 300 index, from Shanghai and Shenzhen Stock Exchanges in China. We use six evaluation criteria to evaluate its performance compared with the back propagation network, support vector machine. The experiment shows that the underlying financial model with deep machine technology has a significant advantage for the prediction of the CSI 300 index.'''\n",
        "\n",
        "abstract_encoded = tokenizer.encode(abstract, max_length=512, pad_to_max_length=True)\n",
        "abstract_encoded = tf.constant(abstract_encoded, dtype=tf.int32)[None, :]\n",
        "print('Title : ')\n",
        "pprint(title)\n",
        "print('\\nAbstract : ')\n",
        "pprint(abstract)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title : \n",
            "'Title'\n",
            "\n",
            "Abstract : \n",
            "('Forecasting stock market direction is always an amazing but challenging '\n",
            " 'problem in finance. Although many popular shallow computational methods '\n",
            " '(such as Backpropagation Network and Support Vector Machine) have '\n",
            " 'extensively been proposed, most algorithms have not yet attained a desirable '\n",
            " 'level of applicability. In this paper, we present a deep learning model with '\n",
            " 'strong ability to generate high level feature representations for accurate '\n",
            " 'financial prediction. Precisely, a stacked denoising autoencoder (SDAE) from '\n",
            " 'deep learning is applied to predict the daily CSI 300 index, from Shanghai '\n",
            " 'and Shenzhen Stock Exchanges in China. We use six evaluation criteria to '\n",
            " 'evaluate its performance compared with the back propagation network, support '\n",
            " 'vector machine. The experiment shows that the underlying financial model '\n",
            " 'with deep machine technology has a significant advantage for the prediction '\n",
            " 'of the CSI 300 index.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-_vAr8z8Hh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = time()\n",
        "bert_output = model(abstract_encoded)\n",
        "xq = tf.nn.l2_normalize(bert_output, axis=1)\n",
        "prediction_time = time() - s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhiyvUxrF4xr",
        "colab_type": "code",
        "outputId": "c1967d2b-d29f-458f-8a86-0ea059b5c026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "s_s = time()\n",
        "cD, aD, cI, aI = search(xq, top_k=5)\n",
        "search_time = time() - s_s\n",
        "total_time = prediction_time + search_time\n",
        "print('\\n'*2)\n",
        "print('Prediction time  :', np.round(prediction_time, 3), 'secs')\n",
        "print('Search time      :', np.round(search_time, 3), 'secs')\n",
        "print('Total time       :', np.round(total_time, 3), 'secs')\n",
        "\n",
        "print('\\n'*2)\n",
        "print('*'*80)\n",
        "for i in range(len(cI)):\n",
        "  print('Title : ')\n",
        "  pprint(embed2Title[cI[i]])\n",
        "  print('\\n')\n",
        "  pprint('Link: semanticscholar.org/paper/'+embed2Paper[cI[i]])\n",
        "  print('*'*80, )\n",
        "print('\\nNeighbours       :', cI )\n",
        "print('Distances        :', np.round(cD, 4))\n",
        "\n",
        "print('\\n'*4)\n",
        "print('*'*80)\n",
        "for i in range(len(aI)):\n",
        "  print('Abstract : ')\n",
        "  pprint(embed2Abstract[aI[i]])\n",
        "  print('\\n')\n",
        "  pprint('Link: semanticscholar.org/paper/'+embed2Paper[aI[i]])\n",
        "  print('*'*80)\n",
        "print('\\nNeighbours       :', aI )\n",
        "print('Distances        :', np.round(aD, 4))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search running on /job:worker/replica:0/task:0/device:TPU:0\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:1\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:2\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:3\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:4\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:5\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:6\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:7\n",
            "\n",
            "\n",
            "\n",
            "Prediction time  : 0.002 secs\n",
            "Search time      : 0.412 secs\n",
            "Total time       : 0.414 secs\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "Title : \n",
            "'A DBN for hyperspectral remote sensing image classification'\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/7552f099b75b6da01e07b16226d10f07458b016d'\n",
            "********************************************************************************\n",
            "Title : \n",
            "('Análisis y comparación de diferentes métodos de reconstrucción de árboles '\n",
            " 'semánticos')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/3384b71d7f25f82214ffcd496d4b6f2867fdc236'\n",
            "********************************************************************************\n",
            "Title : \n",
            "('Fault Detection Algorithm for Power Distribution Network Based on Sparse '\n",
            " 'Self-Encoding Neural Network')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/7bd0b40ff3016c909892efe7ef0077b907cc733f'\n",
            "********************************************************************************\n",
            "Title : \n",
            "'The prediction of character based on recurrent neural network language model'\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/5ec8bbad4d594b104f37f1e04dd9a647e447aab6'\n",
            "********************************************************************************\n",
            "Title : \n",
            "'Leverage estimation for multi-output neural networks'\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/158efab1afa6ff026782ca07b37f7149ef38b137'\n",
            "********************************************************************************\n",
            "\n",
            "Neighbours       : [ 199454 1173940  387229 1149816 1239909]\n",
            "Distances        : [0.5925 0.5961 0.5979 0.5998 0.5998]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('Predicting variations in stock price index has been an important application '\n",
            " 'area of machine learning research. Due to the non-linear and complex nature '\n",
            " 'of the stock market making predictions on stock price index is a challenging '\n",
            " 'and non-trivial task. Deep learning approaches have become an important '\n",
            " 'method in modeling complex relationships in temporal data. In this paper: '\n",
            " '(i) we propose a novel deep learning model that combines multiple pipelines '\n",
            " 'of convolutional neural network and bi-directional long short term memory '\n",
            " 'units. (ii) Proposed model improves prediction performance by 9% upon single '\n",
            " 'pipeline deep learning model and by over a factor of six upon support vector '\n",
            " 'machine regressor model on S&P 500 grand challenge dataset. (iii) We '\n",
            " 'illustrate the improvement in prediction accuracy while minimizing the '\n",
            " 'effects of overfitting by presenting several variations of multiple and '\n",
            " 'single pipeline deep learning models based on different CNN kernel sizes and '\n",
            " 'number of bi-directional LSTM units.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/beac09aebb5ff0eeefba19dc89453af0d7195ac9'\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('Deep learning can achieve the complex function approximation and the '\n",
            " 'characteristics of the input data by studying a deep nonlinear network. At '\n",
            " 'present, one of the most important problems in the study of deep learning is '\n",
            " 'how to construct a reasonable structure. This paper studies the deep '\n",
            " 'learning model of stacked denoising autoencoder (SDA) and the remaining task '\n",
            " 'is to construct its reasonable model. We introduce three effective methods '\n",
            " 'to construct the structure of the SDA. Numerical experiments imply that the '\n",
            " 'structure obtained by the golden section principle performs the best.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/418eb08826ea8d1b26b9dec1308c76c1f025c291'\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('Deep learning has recently received growing interest and attention. It has '\n",
            " 'been successfully applied to many fields. Stock market time-series '\n",
            " 'forecasting is one the most challenging problems for a variety of learning '\n",
            " 'methodologies. In this paper, we studied the integration of deep learning '\n",
            " 'methodologies into stock market forecasting. We evaluated and compared a '\n",
            " 'number of variants of Deep Recurrent Neural Network based on LSTM and GRU. '\n",
            " 'Both bidirectional and unidirectional stacked architectures with '\n",
            " 'multivariate inputs were employed to perform short- and long-term '\n",
            " 'forecasting. The deep learning architectures were also compared to shallow '\n",
            " 'neural networks using S &P500 index historical data. It has been noticed '\n",
            " 'that a stacked LSTM architecture has demonstrated the highest forecasting '\n",
            " 'performance for both short- and long-term.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/decf4a798e3f119d1a304911e336fe88cec6b4ad'\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('In this paper, we propose a novel stock price prediction model based on deep '\n",
            " 'learning. With the success of deep learning algorithms in the field of '\n",
            " 'Artificial Neural Network (ANN), we choose to solve the regression based '\n",
            " 'problems (stock price prediction in our case). Stock price prediction is a '\n",
            " 'challenging problem due to its random movement. This hybrid model is a '\n",
            " 'combination of two well-known networks, Long Short Term Memory (LSTM) and '\n",
            " 'Gated Recurrent Unit (GRU). We choose the S&P 500 historical time series '\n",
            " 'data and use significant evaluation metrics such as mean squared error, mean '\n",
            " 'absolute percentage error etc., that conventional approaches have used. In '\n",
            " 'experiment section, we have described the effectiveness of each of the '\n",
            " 'component of our model along with its performance gain over the '\n",
            " 'state-of-the-art approach. Our prediction model provides less error by '\n",
            " 'considering this random nature (change) for a large scale of data.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/0d7fbdf32e50f2e1a1b689c958cb56ddc4af1c26'\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('Deep learning allows automatically learning multiple levels of '\n",
            " 'representations of the underlying distribution of the data to be modeled. In '\n",
            " 'this work, a specific implementation called stacked denoising autoencoders '\n",
            " 'is explored. We contribute by demonstrating that this kind of representation '\n",
            " 'coupled to a SVM improves classification error on MNIST over the usual deep '\n",
            " 'learning approach where a logistic regression layer is added to the stack of '\n",
            " 'denoising autoencoders.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/bbe0b974a598302171b684cc548fff28a61ffc12'\n",
            "********************************************************************************\n",
            "\n",
            "Neighbours       : [ 214864 1059862  657512 1026378  598137]\n",
            "Distances        : [0.1482 0.1583 0.1758 0.2013 0.2202]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmFJS0xIc9us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}