{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "build_index_and_search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8wAw2JV6F4Am",
        "outputId": "817816f3-3089-49c6-b995-966ffedba882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "!gdown --id \"10LV9QbZOkUyOzR4nh8hxesoKJhpmvpM9\"   # citation vectors\n",
        "!gdown --id \"1-23aNm7j0bnycvyd_OaQfofVYPTewgOI\"   # abstract vectors\n",
        "!gdown --id \"1NyUQwgUNj9bFsiCnZ2TfKmWn5r-Y6wav\"   # TitlesIdAbstractsEmbedIds\n",
        "!wget 'https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar'\n",
        "!tar -xvf 'scibert_scivocab_uncased.tar'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10LV9QbZOkUyOzR4nh8hxesoKJhpmvpM9\n",
            "To: /content/CitationSimilarityVectors106Epochs.npy\n",
            "2.59GB [00:26, 99.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-23aNm7j0bnycvyd_OaQfofVYPTewgOI\n",
            "To: /content/AbstractSimVectors.npy\n",
            "2.59GB [00:46, 55.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NyUQwgUNj9bFsiCnZ2TfKmWn5r-Y6wav\n",
            "To: /content/TitlesIdsAbstractsEmbedIdsCOMPLETE_12-30-19.json.gzip\n",
            "432MB [00:05, 79.5MB/s]\n",
            "--2019-12-31 01:06:25--  https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar\n",
            "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.144.72\n",
            "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.144.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 442460160 (422M) [application/x-tar]\n",
            "Saving to: ‘scibert_scivocab_uncased.tar’\n",
            "\n",
            "scibert_scivocab_un 100%[===================>] 421.96M  47.3MB/s    in 8.6s    \n",
            "\n",
            "2019-12-31 01:06:34 (48.8 MB/s) - ‘scibert_scivocab_uncased.tar’ saved [442460160/442460160]\n",
            "\n",
            "scibert_scivocab_uncased/\n",
            "scibert_scivocab_uncased/vocab.txt\n",
            "scibert_scivocab_uncased/pytorch_model.bin\n",
            "scibert_scivocab_uncased/config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP2AqdEiQhbS",
        "colab_type": "code",
        "outputId": "9dc6fb14-39b1-469f-c6bb-9502022919d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install transformers --quiet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 450kB 3.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 860kB 11.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 17.6MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SGov6e8uGO3B",
        "outputId": "6938dd59-e5d2-4da3-865d-6eda647736b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "print('TensorFlow:', tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "TensorFlow: 2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iht3WQa3H_g6",
        "outputId": "3ed5d9b2-df2f-45ce-c542-57ff86c681a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.11.125.18:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: 10.11.125.18:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.11.125.18:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ks95sxuIKbR",
        "outputId": "d30cea60-e050-48a4-ef07-c1557bbf7fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "if tpu:\n",
        "  workers = ['/job:worker/replica:0/task:0/device:TPU:'+str(i) for i in range(8)]\n",
        "  print(workers)\n",
        "  gpu =''\n",
        "if tf.config.experimental.list_physical_devices('GPU'):\n",
        "  gpu = 'gpu'\n",
        "  workers = ['/GPU:0']\n",
        "  print(workers)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/job:worker/replica:0/task:0/device:TPU:0', '/job:worker/replica:0/task:0/device:TPU:1', '/job:worker/replica:0/task:0/device:TPU:2', '/job:worker/replica:0/task:0/device:TPU:3', '/job:worker/replica:0/task:0/device:TPU:4', '/job:worker/replica:0/task:0/device:TPU:5', '/job:worker/replica:0/task:0/device:TPU:6', '/job:worker/replica:0/task:0/device:TPU:7']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uByeXRrVO78_",
        "colab": {}
      },
      "source": [
        "class Index:\n",
        "    def __init__(self, embeddings, worker):\n",
        "        self.embeddings = tf.math.l2_normalize(embeddings, axis=1)\n",
        "        self.worker = worker\n",
        "\n",
        "    @tf.function\n",
        "    def search(self, query_vector):\n",
        "      with tf.device(worker):\n",
        "        dot_product = tf.reduce_sum(tf.multiply(self.embeddings, query_vector), axis=1)\n",
        "        distances = 1 - dot_product\n",
        "        sorted_indices =  tf.argsort(distances)\n",
        "        nearest_distances = tf.gather(distances, sorted_indices)\n",
        "        return nearest_distances[:20], sorted_indices[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DFloyWt7G8ts",
        "colab": {}
      },
      "source": [
        "citations_embeddings = np.load('CitationSimilarityVectors106Epochs.npy')\n",
        "abstract_embeddings = np.load('AbstractSimVectors.npy')\n",
        "assert citations_embeddings.shape == abstract_embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AB8L4sA-H2nf",
        "outputId": "8621c81d-0c3b-43dd-e153-f2f9b052e91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "if tpu:\n",
        "  # Discarding last 4 vectors to make number of vectors divisible by 8\n",
        "  citations_embeddings = np.split(citations_embeddings[:-4], 8, axis=0)\n",
        "  abstract_embeddings = np.split(abstract_embeddings[:-4], 8, axis=0)\n",
        "  vecs_per_index = citations_embeddings[0].shape[0]\n",
        "  print('Vectors per index :', vecs_per_index)\n",
        "elif gpu:\n",
        "  vecs_per_index = citations_embeddings.shape[0]\n",
        "  print('Vectors per index :', vecs_per_index)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_or_sections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-86067abff86d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# Discarding last 4 vectors to make number of vectors divisible by 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mcitations_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcitations_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mabstract_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstract_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mvecs_per_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcitations_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msplit\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0msections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_or_sections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             raise ValueError(\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HoEA0SqeJW4n",
        "outputId": "92a8f130-692e-4f34-ff1e-13a2c7cf74db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "citation_indices = []\n",
        "abstract_indices = []\n",
        "if gpu:\n",
        "  for i, worker in enumerate(workers):\n",
        "    with tf.device(worker):\n",
        "      print('Building index with {} vectors on {}'.format(citations_embeddings.shape[0], worker))\n",
        "      citation_indices.append(Index(citations_embeddings, worker))\n",
        "      abstract_indices.append(Index(abstract_embeddings, worker))\n",
        "elif tpu:\n",
        "  ## Place 1/8 of total embeddings on each TPU core\n",
        "  for i, worker in enumerate(workers):\n",
        "    with tf.device(worker):\n",
        "      print('Building index with {} vectors on {}'.format(citations_embeddings[i].shape[0],worker))\n",
        "      citation_indices.append(Index(citations_embeddings[i], worker))\n",
        "      abstract_indices.append(Index(abstract_embeddings[i], worker))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:0\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:1\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:2\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:3\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:4\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:5\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:6\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W5r4LmcVqGAZ",
        "colab": {}
      },
      "source": [
        "def search(xq, top_k=10):\n",
        "  cD, cI = [], []\n",
        "  aD, aI = [], []\n",
        "  if tpu:\n",
        "    r = 8\n",
        "  else:\n",
        "    r = 1\n",
        "  for i in range(r):\n",
        "    print('Search running on {}'.format(citation_indices[i].worker))\n",
        "    cd, cidx = citation_indices[i].search(xq)\n",
        "    ad, aidx = abstract_indices[i].search(xq)\n",
        "\n",
        "    cD.extend(cd.numpy())\n",
        "    aD.extend(ad.numpy())\n",
        "\n",
        "    cI.extend(i*vecs_per_index + cidx.numpy())\n",
        "    aI.extend(i*vecs_per_index + aidx.numpy())\n",
        "\n",
        "  cid_sorted = np.argsort(cD)[:top_k]\n",
        "  aid_sorted = np.argsort(aD)[:top_k]\n",
        "\n",
        "  cD = np.array(cD)[cid_sorted]\n",
        "  aD = np.array(aD)[aid_sorted]\n",
        "\n",
        "  cI = np.array(cI)[cid_sorted]\n",
        "  aI = np.array(aI)[aid_sorted]\n",
        "  return cD, aD, cI, aI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syc0k8Yi4rcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.saved_model.load('gs://tfworld/saved_models')\n",
        "tokenizer = BertTokenizer(vocab_file='scibert_scivocab_uncased/vocab.txt')\n",
        "\n",
        "df = pd.read_json('/content/TitlesIdsAbstractsEmbedIdsCOMPLETE_12-30-19.json.gzip', compression = 'gzip')\n",
        "embed2Title = pd.Series(df['title'].values,index=df['EmbeddingID']).to_dict()\n",
        "embed2Abstract = pd.Series(df['paperAbstract'].values,index=df['EmbeddingID']).to_dict()\n",
        "embed2Paper = pd.Series(df['id'].values,index=df['EmbeddingID']).to_dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxkcuP0CDNKM",
        "colab_type": "code",
        "outputId": "f3e9d398-6690-42f8-e672-e65dc728148a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# embed_id = 70000\n",
        "# title = embed2Title[embed_id]\n",
        "title = 'Title'\n",
        "#abstract = embed2Abstract[embed_id]\n",
        "abstract = '''Financial modelling for assets'''\n",
        "\n",
        "abstract_encoded = tokenizer.encode(abstract, max_length=512, pad_to_max_length=True)\n",
        "abstract_encoded = tf.constant(abstract_encoded, dtype=tf.int32)[None, :]\n",
        "print('Title : ')\n",
        "pprint(title)\n",
        "print('\\nAbstract : ')\n",
        "pprint(abstract)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title : \n",
            "'Title'\n",
            "\n",
            "Abstract : \n",
            "'Financial modelling for assets'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhiyvUxrF4xr",
        "colab_type": "code",
        "outputId": "1086abcd-4c31-4e5c-b3d9-9fa22d99f4f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "s = time()\n",
        "bert_output = model(abstract_encoded)\n",
        "xq = tf.nn.l2_normalize(bert_output, axis=1)\n",
        "e_p = time()\n",
        "\n",
        "cD, aD, cI, aI = search(xq, top_k=5)\n",
        "e_s = time()\n",
        "print('\\n'*2)\n",
        "print('Prediction time  :', np.round(e_p-s, 3), 'secs')\n",
        "print('Search time      :', np.round(e_s-e_p, 3), 'secs')\n",
        "print('Total time       :', np.round(e_s - s, 3), 'secs')\n",
        "\n",
        "print('\\n'*2)\n",
        "print('*'*80)\n",
        "for i in range(len(cI)):\n",
        "  print('Title : ')\n",
        "  pprint(embed2Title[cI[i]])\n",
        "  print('\\n')\n",
        "  pprint('Link: semanticscholar.org/paper/'+embed2Paper[cI[i]])\n",
        "  print('*'*80, )\n",
        "print('\\nNeighbours       :', cI )\n",
        "print('Distances        :', np.round(cD, 4))\n",
        "\n",
        "print('\\n'*4)\n",
        "print('*'*80)\n",
        "for i in range(len(aI)):\n",
        "  print('Abstract : ')\n",
        "  pprint(embed2Abstract[aI[i]])\n",
        "  print('\\n')\n",
        "  pprint('Link: semanticscholar.org/paper/'+embed2Paper[aI[i]])\n",
        "  print('*'*80)\n",
        "print('\\nNeighbours       :', aI )\n",
        "print('Distances        :', np.round(aD, 4))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search running on /job:worker/replica:0/task:0/device:TPU:0\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:1\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:2\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:3\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:4\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:5\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:6\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:7\n",
            "\n",
            "\n",
            "\n",
            "Prediction time  : 0.236 secs\n",
            "Search time      : 5.604 secs\n",
            "Total time       : 5.84 secs\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "Title : \n",
            "('Approach for improving receiver performance in loss-free handovers in DVB-H '\n",
            " 'networks')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/85fabe4a29a5eea59d78e3e5005c43837ad61837'\n",
            "********************************************************************************\n",
            "Title : \n",
            "'Qualification of the Joints for the ITER Central Solenoid'\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/b2c88eb44c152fb189edf2113466621a2d54dcee'\n",
            "********************************************************************************\n",
            "Title : \n",
            "('Solar energy as alternative power supply for communication system IEEE '\n",
            " '802.15.4 standard')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/dcb499aefe2182be7f25033579f0bf17ef8bf20c'\n",
            "********************************************************************************\n",
            "Title : \n",
            "('Combinatorial invariance of Kazhdan–Lusztig–Vogan polynomials for fixed '\n",
            " 'point free involutions')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/1ab584117236609cb06e26a5e01103e43d803530'\n",
            "********************************************************************************\n",
            "Title : \n",
            "'The Bruhat order on clans'\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/443dcc67cee280fe937617accdf59197ff5d3c1d'\n",
            "********************************************************************************\n",
            "\n",
            "Neighbours       : [  28327  873572  629316  927389 1035631]\n",
            "Distances        : [0.6475 0.6699 0.6778 0.6818 0.6822]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('In this study we are trying with the neural network model to make an '\n",
            " 'effective analysis for corporation credit rating. A 12-25-1 three-layer '\n",
            " 'feedforward neural network using the backpropagation and Levenberg-Marquardt '\n",
            " 'algorithms has been used in the proposed artificial neural network. The '\n",
            " 'experiment results show that this network is efficient and forms a useful '\n",
            " 'tool for the prediction of corporation credit rating.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/732656b397bc93e3fcb7a85087e376a781524b46'\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('This paper explores the effects of a firm’s cash flow systematic risk on its '\n",
            " 'optimal capital structure. In a model where firms are allowed to borrow '\n",
            " 'resources from a competitive lending sector, those with cash flows more '\n",
            " 'correlated with the aggregate economy (i.e., firms with riskier assets in '\n",
            " 'place) choose a lower leverage given their higher expected financing costs. '\n",
            " 'On the other hand, less risky firms, having lower expected financing costs, '\n",
            " 'optimally choose to issue more debt to exploit a tax advantage. The model '\n",
            " 'predicts that cash flow systematic risk is negatively correlated with '\n",
            " 'leverage and corporate bond yields.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/56b9d3a8b6d5a850b0e37ad0c3695e884c7d5e46'\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('In this paper, we propose a robust and novel ensemble model for Net asset '\n",
            " 'value prediction of Mutual fund. The proposed model is constituted of two '\n",
            " 'non-linear models: Radial basis function (RBF) and Functional link '\n",
            " 'artificial neural network (FLANN). In order to improve the prediction '\n",
            " 'performance of the hybrid model a boosting technique is used. The sum of the '\n",
            " 'weighted outputs of the two models is compared with the target values to '\n",
            " 'minimize the mean square error. The proposed model shows improved '\n",
            " 'performance in terms of MAPE and RMSE values in comparison to each '\n",
            " 'individual model.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/39ba7a59ce220ee247b97d4759cf5eee3d7261b5'\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('We discuss extensions of reduced-form and structural models for pricing '\n",
            " 'credit risky securities to portfolio simulation and valuation. Stochasticity '\n",
            " 'in interest rates and credit spreads is captured via reduced-form models and '\n",
            " 'is incorporated with a default and migration model based on the structural '\n",
            " 'credit risk modelling approach. Calculated prices are consistent with '\n",
            " 'observed prices and the term structure of default-free and defaultable '\n",
            " 'interest rates. Three applications are discussed: (i) study of the '\n",
            " 'inter-temporal price sensitivity of credit bonds and the sensitivity of '\n",
            " 'future portfolio valuation with respect to changes in interest rates, '\n",
            " 'default probabilities, recovery rates and rating migration, (ii) study of '\n",
            " 'the structure of credit risk by investigating the impact of disparate risk '\n",
            " 'factors on portfolio risk, and (iii) tracking of corporate bond indices via '\n",
            " 'simulation and optimisation models. In particular, we study the effect of '\n",
            " 'uncertainty in credit spreads and interest rates on the overall risk of a '\n",
            " 'credit portfolio, a topic that has been recently discussed by Kiesel et al. '\n",
            " '[The structure of credit risk: spread volatility and ratings transitions. '\n",
            " 'Technical report, Bank of England, ISSN 1268-5562, 2001], but has been '\n",
            " 'otherwise mostly neglected. We find that spread risk and interest rate risk '\n",
            " 'are important factors that do not diversify away in a large portfolio '\n",
            " 'context, especially when high-quality instruments are considered.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/17ef2645e2928e73b1a75172c702d098e5cc380e'\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('Illiquidity and market impact refer to the situation where it may be costly '\n",
            " 'or difficult to trade a desired quantity of assets over a desire period of '\n",
            " 'time. In this paper, we formulate a simple model of dynamic portfolio choice '\n",
            " 'that incorporates liquidity effects. The resulting problem is a stochastic '\n",
            " 'linear quadratic control problem where liquidity costs are modeled as a '\n",
            " 'quadratic penalty on the trading rate. Though easily computable via Riccati '\n",
            " 'equations, we also derive a multiple time scale asymptotic expansion of the '\n",
            " 'value function and optimal trading rate in the regime of vanishing market '\n",
            " 'impact costs. This expansion reveals an interesting but intuitive '\n",
            " 'relationship between the optimal trading rate for the “illiquid” problem and '\n",
            " 'the classical Merton model for dynamic portfolio selection in perfectly '\n",
            " 'liquid markets. It also gives rise to the notion of a “liquidity time scale” '\n",
            " 'which shows how trading horizon and market impact costs affect the optimal '\n",
            " 'trading rate.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/72ad391a6344d8cf6b4242c5867a11a2b811ff1a'\n",
            "********************************************************************************\n",
            "\n",
            "Neighbours       : [371932 835910 965602 150355 148662]\n",
            "Distances        : [0.5284 0.5302 0.5309 0.5345 0.5452]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmFJS0xIc9us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}