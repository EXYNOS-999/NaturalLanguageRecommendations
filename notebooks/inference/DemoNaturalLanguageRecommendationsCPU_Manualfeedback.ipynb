{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemoNaturalLanguageRecommendationsCPU-Manualfeedback.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santosh-Gupta/NaturalLanguageRecommendations/blob/master/notebooks/inference/DemoNaturalLanguageRecommendationsCPU_Manualfeedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9eERu8JP9r7",
        "colab_type": "text"
      },
      "source": [
        "This is our simple Colab demo notebook, which can run on a CPU instance, though it may crash a regular colab CPU instance since it's memory intensive. If that happens, a message should appear on the bottom left asking if you would like to switch to a 25 gb RAM instance, which will be more than enough memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3YuDoc3QUBv",
        "colab_type": "text"
      },
      "source": [
        "If you would like play with using a GPU or TPU for inference, please see our advanced demo notebook here https://colab.research.google.com/github/Santosh-Gupta/NaturalLanguageRecommendations/blob/master/notebooks/inference/build_index_and_search.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8wAw2JV6F4Am",
        "outputId": "3d2557fe-93f5-4157-928d-cbe309217ac1",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        }
      },
      "source": [
        "#@title Download and load model, embeddings, and data, will take a several minutes. Double click on this to pop open the hood and checkout the code.\n",
        "\n",
        "!gdown --id \"10LV9QbZOkUyOzR4nh8hxesoKJhpmvpM9\"   # citation vectors\n",
        "# !gdown --id \"1-8gmT9cQpOUoZ_HzEaT9Xz6qfeVooAFn\"\n",
        "!gdown --id \"1-23aNm7j0bnycvyd_OaQfofVYPTewgOI\"   # abstract vectors\n",
        "!gdown --id \"1NyUQwgUNj9bFsiCnZ2TfKmWn5r-Y6wav\"   # TitlesIdAbstractsEmbedIds\n",
        "!gdown --id \"1wIRsAApaE2L7E1fjnDOSSVBG1fY-LT9i\" # Model\n",
        "!wget 'https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar'\n",
        "!tar -xvf 'scibert_scivocab_uncased.tar'\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('tfworld.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('')\n",
        "\n",
        "!pip install transformers --quiet\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "print('TensorFlow:', tf.__version__)\n",
        "\n",
        "!gdown --id \"1owiHXcDyTYecOq0Y27bOk0s4jgxmukTs\"\n",
        "!pip install --upgrade --quiet gspread\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "scope = ['https://www.googleapis.com/auth/spreadsheets']\n",
        "credentials = ServiceAccountCredentials.from_json_keyfile_name('worksheet1.worksheet2.worksheet3.json', scope)\n",
        "gc = gspread.authorize(credentials)\n",
        "worksheet2 = gc.open_by_key('1AU37NTxsafd9GNhum2yR3iCux9nT9GAN5Bn4HaWcyU4').sheet1\n",
        "worksheet3 = gc.open_by_key('1Vaxn8rWz0CufCeDF_Ip9lzErZjK3AUA3g02fYMBe5P4').sheet1\n",
        "\n",
        "print('Loading Embeddings')\n",
        "citations_embeddings = np.load('CitationSimilarityVectors106Epochs.npy')\n",
        "abstract_embeddings = np.load('AbstractSimVectors.npy')\n",
        "assert citations_embeddings.shape == abstract_embeddings.shape\n",
        "\n",
        "normalizedC = tf.nn.l2_normalize(citations_embeddings, axis=1)\n",
        "normalizedA = tf.nn.l2_normalize(abstract_embeddings, axis=1) \n",
        "\n",
        "print('Loading Model')\n",
        "model = tf.saved_model.load('tfworld/inference_model/')\n",
        "print('laoding Tokenizer')\n",
        "tokenizer = BertTokenizer(vocab_file='scibert_scivocab_uncased/vocab.txt')\n",
        "\n",
        "print('Loading Semantic Scholar CS data, almost done . . .')\n",
        "df = pd.read_json('/content/TitlesIdsAbstractsEmbedIdsCOMPLETE_12-30-19.json.gzip', compression = 'gzip')\n",
        "embed2Title = pd.Series(df['title'].values,index=df['EmbeddingID']).to_dict()\n",
        "embed2Abstract = pd.Series(df['paperAbstract'].values,index=df['EmbeddingID']).to_dict()\n",
        "embed2Paper = pd.Series(df['id'].values,index=df['EmbeddingID']).to_dict()\n",
        "\n",
        "import sys, os\n",
        "\n",
        "# Disable\n",
        "def blockPrint():\n",
        "    sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "# Restore\n",
        "def enablePrint():\n",
        "    sys.stdout = sys.__stdout__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10LV9QbZOkUyOzR4nh8hxesoKJhpmvpM9\n",
            "To: /content/CitationSimilarityVectors106Epochs.npy\n",
            "2.59GB [00:20, 126MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-23aNm7j0bnycvyd_OaQfofVYPTewgOI\n",
            "To: /content/AbstractSimVectors.npy\n",
            "2.59GB [00:41, 62.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NyUQwgUNj9bFsiCnZ2TfKmWn5r-Y6wav\n",
            "To: /content/TitlesIdsAbstractsEmbedIdsCOMPLETE_12-30-19.json.gzip\n",
            "432MB [00:06, 66.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wIRsAApaE2L7E1fjnDOSSVBG1fY-LT9i\n",
            "To: /content/tfworld.zip\n",
            "411MB [00:06, 62.0MB/s]\n",
            "--2020-01-12 19:35:43--  https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar\n",
            "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.218.232\n",
            "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.218.232|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 442460160 (422M) [application/x-tar]\n",
            "Saving to: ‘scibert_scivocab_uncased.tar’\n",
            "\n",
            "scibert_scivocab_un 100%[===================>] 421.96M  35.3MB/s    in 12s     \n",
            "\n",
            "2020-01-12 19:35:56 (34.0 MB/s) - ‘scibert_scivocab_uncased.tar’ saved [442460160/442460160]\n",
            "\n",
            "scibert_scivocab_uncased/\n",
            "scibert_scivocab_uncased/vocab.txt\n",
            "scibert_scivocab_uncased/pytorch_model.bin\n",
            "scibert_scivocab_uncased/config.json\n",
            "\u001b[K     |████████████████████████████████| 450kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 13.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 870kB 21.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "TensorFlow 2.x selected.\n",
            "TensorFlow: 2.1.0-rc1\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1owiHXcDyTYecOq0Y27bOk0s4jgxmukTs\n",
            "To: /content/worksheet1.worksheet2.worksheet3.json\n",
            "100% 2.35k/2.35k [00:00<00:00, 961kB/s]\n",
            "Loading Embeddings\n",
            "Loading Model\n",
            "laoding Tokenizer\n",
            "Loading Semantic Scholar CS data. This will take a few more minutes, almost done . . .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVzix3jhPIYx",
        "colab_type": "text"
      },
      "source": [
        "Use cell below to search for papers. Our model was trained on using full abstracts using the 'query', so the model performs better with longer queries, but the model works surprisingly well with short queries as well. Give it a try."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lMVIjtwQm-1",
        "colab_type": "text"
      },
      "source": [
        "Our model was trained to use a citation emedding as a label, but we found out running similarity on our abstract embeddings results in surprisingly robust results as well, so we included both. The first half of the results are from the citation embeddings, the second half are from the abstract embeddings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJJnXM5BiE-m",
        "colab_type": "code",
        "outputId": "b1e1328e-f4e9-44e5-dbee-69e524e62797",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "query = \"The effect of negative sampling on embedding quality. noise contrastive sampling in vector representation. \" #@param {type:\"string\"}\n",
        "\n",
        "top_k_results = 50 #@param {type:\"integer\"}\n",
        "\n",
        "if top_k_results%2 == 0:\n",
        "    halfA = halfC = int(top_k_results/2)\n",
        "else:\n",
        "    halfC = int(top_k_results/2) + 1\n",
        "    halfA = int(top_k_results/2) \n",
        "\n",
        "abstract_encoded = tokenizer.encode(query, max_length=512, pad_to_max_length=True)\n",
        "abstract_encoded = tf.constant(abstract_encoded, dtype=tf.int32)[None, :]\n",
        "print('\\nQuery : ')\n",
        "pprint(query)\n",
        "\n",
        "s = time()\n",
        "bert_output = model(abstract_encoded)\n",
        "xq = tf.nn.l2_normalize(bert_output, axis=1)\n",
        "prediction_time = time() - s\n",
        "\n",
        "simNumpyC = np.matmul(normalizedC, tf.transpose(xq))\n",
        "simNumpyCTopK = (-simNumpyC[:,0]).argsort()[:halfC]\n",
        "simNumpyC_oTopK = -np.sort(-simNumpyC[:,0])[:halfC]\n",
        "allCit = np.vstack((simNumpyCTopK , simNumpyC_oTopK) )\n",
        "del simNumpyC\n",
        "\n",
        "simNumpyA = np.matmul(normalizedA, tf.transpose(xq))\n",
        "simNumpyATopK = (-simNumpyA[:,0]).argsort()[:halfA]\n",
        "simNumpyA_oTopK = -np.sort(-simNumpyA[:,0])[:halfA]\n",
        "allAbs = np.vstack((simNumpyATopK , simNumpyA_oTopK) )\n",
        "del simNumpyA\n",
        "\n",
        "allResults = np.concatenate((allAbs, allCit), axis = 1)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print('------ Nearest papers  -----------------------------------------------------------')\n",
        "print('\\n')\n",
        "\n",
        "for embed in allResults[0]:\n",
        "    print('---------------')\n",
        "    print('-------')\n",
        "    print('---')\n",
        "    title = embed2Title[int(embed)]\n",
        "    abstractR = embed2Abstract[int(embed)]\n",
        "    paperId = embed2Paper[int(embed)]\n",
        "    print('Title: ', title)\n",
        "    print('\\nAbstract : ')\n",
        "    pprint(abstractR)\n",
        "    # print('\\n')\n",
        "    print('\\nLink: https://www.semanticscholar.org/paper/'+paperId)\n",
        "    print('---')\n",
        "    print('-------')\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Query : \n",
            "('The effect of negative sampling on embedding quality. noise contrastive '\n",
            " 'sampling in vector representation. ')\n",
            "\n",
            "\n",
            "------ Nearest papers  -----------------------------------------------------------\n",
            "\n",
            "\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Fried Binary Embedding for High-Dimensional Visual Features\n",
            "\n",
            "Abstract : \n",
            "('Most existing binary embedding methods prefer compact binary codes '\n",
            " '(b-dimensional) to avoid high computational and memory cost of projecting '\n",
            " 'high-dimensional visual features (d-dimensional, b')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/16a0fde0ee401384ac0b425192a990eeb9c02018\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Noise-Contrastive Estimation Based on Relative Neighbour Sampling for Unsupervised Image Embedding Learning\n",
            "\n",
            "Abstract : \n",
            "('Many unsupervised learning algorithms have been proposed to avoid the '\n",
            " 'inconvenience of data labeling. The nature of neural networks is also '\n",
            " 'gradually being explored by unsupervised learning. In this paper, we focus '\n",
            " 'on the sampling strategy for unsupervised images embedding learning via '\n",
            " 'instance discrimination. A new sampling method is proposed based on the '\n",
            " 'observation that different samples contribute unequally to training, which '\n",
            " 'pays more attention to the neighbours. The proposed sampling method is '\n",
            " 'beneficial and efficient for images embedding learning. The results on '\n",
            " 'benchmark data show that the proposed sampling method is robust and '\n",
            " 'outperforms the compared method.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/9b87f58b620d9de5f360f6dccdcedfffd99c1408\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Fast binary embeddings with Gaussian circulant matrices\n",
            "\n",
            "Abstract : \n",
            "('We consider the problem of encoding a finite set of vectors into a small '\n",
            " 'number of bits while approximately retaining information on the angular '\n",
            " 'distances between the vectors. By deriving improved variance bounds related '\n",
            " 'to binary Gaussian circulant embeddings, we largely fix a gap in the proof '\n",
            " 'of the best known fast binary embedding method. Our bounds also show that '\n",
            " 'well-spreadness assumptions on the data vectors, which were needed in '\n",
            " 'earlier work on variance bounds, are unnecessary. In addition, we propose a '\n",
            " 'new binary embedding with a faster running time on sparse data.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/6db4ca65aca67f06b7107a85d03df3e05c69a584\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Dimensionality Reduction for Classification through Visualisation Using L1SNE\n",
            "\n",
            "Abstract : \n",
            "('Dimensionality Reduction algorithms have wide precedent for use in '\n",
            " 'preprocessing for classification problems. This paper presents a new '\n",
            " 'algorithm, based on a modification to Stochastic Neighbour Embedding and '\n",
            " 't-Distributed SNE to use the Laplacian distribution instead of, '\n",
            " 'respectively, the Gaussian Distribution and a mismatched pair of the '\n",
            " 'Gaussian Distribution and Student’s t-Distribution. Experimental results are '\n",
            " 'presented to demonstrate that this modification yields improvement.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/dc93d28eefff65de1eb9f9c3d0e73aacf6722008\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Unsupervised image embedding using nonparametric statistics\n",
            "\n",
            "Abstract : \n",
            "('Embedding images into a low dimensional space has a wide range of '\n",
            " 'applications: visualization, clustering, and pre-processing for supervised '\n",
            " 'learning. Traditional dimension reduction algorithms assume that the '\n",
            " 'examples densely populate the manifold. Image databases tend to break this '\n",
            " 'assumption, having isolated islands of similar images instead. In this work, '\n",
            " 'we propose a novel approach that embeds images into a low dimensional '\n",
            " 'Euclidean space, while preserving local image similarities based on their '\n",
            " 'scale invariant feature transform (SIFT) vectors. We make no neighborhood '\n",
            " 'assumptions in our embedding. Our algorithm can also embed the images in a '\n",
            " 'discrete grid, useful for many visualization tasks. We demonstrate the '\n",
            " 'algorithm on images with known categories and compare our accuracy favorably '\n",
            " 'to those of competing algorithms.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/af729d4e5fa9796e39ad03f7c61b290d1d45c14e\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Exploiting sparse representations in very high-dimensional feature spaces obtained from patch-based processing\n",
            "\n",
            "Abstract : \n",
            "('Use of high-dimensional feature spaces in a system has standard problems '\n",
            " 'that must be addressed such as the high calculation costs, storage demands, '\n",
            " 'and training requirements. To partially circumvent this problem, we propose '\n",
            " 'the conjunction of the very high-dimensional feature space and image '\n",
            " 'patches. This union allows for the image patches to be efficiently '\n",
            " 'represented as sparse vectors while taking advantage of the high-dimensional '\n",
            " 'properties. The key to making the system perform efficiently is the use of a '\n",
            " 'sparse histogram representation for the color space which makes the '\n",
            " 'calculations largely independent of the feature space dimension. The system '\n",
            " 'can operate under multiple Lp norms or mixed metrics which allows for '\n",
            " 'optimized metrics for the feature vector. An optimal tree structure is also '\n",
            " 'introduced for the approximate nearest neighbor tree to aid in patch '\n",
            " 'classification. It is shown that the system can be applied to various '\n",
            " 'applications and used effectively.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/f07a5a797ea18ced878c84e3ff724800d96ad74a\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Investigation on Projection Space Pairs in Neighbor Embedding Algorithms\n",
            "\n",
            "Abstract : \n",
            "('In order to achieve superior performance, various projection space pairs '\n",
            " '(PSPs) in neighbor embedding (NE) algorithms are introduced aiming to '\n",
            " 'satisfy manifold assumption better. However, the comparison of theses PSPs '\n",
            " 'has not been given much importance in previous researches, which could be a '\n",
            " 'guiding factor for choosing better PSPs before executing the whole neighbor '\n",
            " 'embedding process. Besides, evaluation criterions of final results like Peak '\n",
            " 'Signal to Noise Ratio (PSNR) cannot represent the exact performance of '\n",
            " 'non-linear PSPs due to the non-linear back projection process. To overcome '\n",
            " 'these limitations, we compare different PSPs by introducing an efficient '\n",
            " 'technique using cosine similarity and histogram approach. Experimental '\n",
            " 'results demonstrate the effectiveness of the proposed evaluation method. '\n",
            " 'Moreover, we also identify that non-linear PSPs could obtain superior '\n",
            " 'performance only if the non-linear back projection process is well handled.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/a0cc89ad98185bc28f8277f3af45f66f19f8ea5f\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Uncorrelated Discriminant Locality Aware Embedding for Face Recognition\n",
            "\n",
            "Abstract : \n",
            "('In this paper, we describe a feature extraction algorithm called '\n",
            " 'Discriminant Uncorrelated Locality Aware Embedding, DULAM for short, which '\n",
            " 'is based on LPP (locality preserving projection). LPP can preserve the local '\n",
            " 'structure of the data, but does not take the class information into account, '\n",
            " 'besides, the extracted feature might be highly correlated. To overcome these '\n",
            " 'drawbacks, DULAM is proposed, which not only preserves the locality of the '\n",
            " 'data, but also takes the class information into consideration, and an '\n",
            " 'uncorrelated constraint is also imposed to reduce the redundancy, thus it '\n",
            " 'betters the recognition performance. Experiments validate the correctness '\n",
            " 'and effectiveness of the algorithm.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/8be9792649c56973fb7a6880be0b3cc29104aa66\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Fast binary embedding via circulant downsampled matrix\n",
            "\n",
            "Abstract : \n",
            "('Binary embedding of high-dimensional data aims to produce low-dimensional '\n",
            " 'binary codes while preserving discriminative power. State-of-the-art methods '\n",
            " 'often suffer from high computation and storage costs. We present a simple '\n",
            " 'and fast embedding scheme by first downsampling N-dimensional data into '\n",
            " 'M-dimensional data and then multiplying the data with an M×M circulant '\n",
            " 'matrix. Our method requires O(N + M log M) computation and O(N) storage '\n",
            " 'costs. We prove if data have sparsity, our scheme can achieve '\n",
            " 'similarity-preserving well. Experiments further demonstrate that though our '\n",
            " 'method is cost-effective and fast, it still achieves comparable performance '\n",
            " 'in image applications.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/fde9a7dbf7608e4196fb87326dda16ee0599812d\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Learning a hierarchical image manifold for Web image classification\n",
            "\n",
            "Abstract : \n",
            "('Image classification is an essential task in content-based image retrieval. '\n",
            " 'However, due to the semantic gap between low-level visual features and '\n",
            " 'high-level semantic concepts, and the diversification of Web images, the '\n",
            " 'performance of traditional classification approaches is far from users’ '\n",
            " 'expectations. In an attempt to reduce the semantic gap and satisfy the '\n",
            " 'urgent requirements for dimensionality reduction, high-quality retrieval '\n",
            " 'results, and batch-based processing, we propose a hierarchical image '\n",
            " 'manifold with novel distance measures for calculation. Assuming that the '\n",
            " 'images in an image set describe the same or similar object but have various '\n",
            " 'scenes, we formulate two kinds of manifolds, object manifold and scene '\n",
            " 'manifold, at different levels of semantic granularity. Object manifold is '\n",
            " 'developed for object-level classification using an algorithm named extended '\n",
            " 'locally linear embedding (ELLE) based on intra- and inter-object difference '\n",
            " 'measures. Scene manifold is built for scene-level classification using an '\n",
            " 'algorithm named locally linear submanifold extraction (LLSE) by combining '\n",
            " 'linear perturbation and region growing. Experimental results show that our '\n",
            " 'method is effective in improving the performance of classifying Web images.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/f6d54880186b96af30230445461aae323e3ab4e6\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Fast Orthogonal Projection Based on Kronecker Product\n",
            "\n",
            "Abstract : \n",
            "('We propose a family of structured matrices to speed up orthogonal '\n",
            " 'projections for high-dimensional data commonly seen in computer vision '\n",
            " 'applications. In this, a structured matrix is formed by the Kronecker '\n",
            " 'product of a series of smaller orthogonal matrices. This achieves O(d log d) '\n",
            " 'computational complexity and O(log d) space complexity for d-dimensional '\n",
            " 'data, a drastic improvement over the standard unstructured projections whose '\n",
            " 'computational and space complexities are both O(d2). The proposed structured '\n",
            " 'matrices are applicable to a number of application domains, and are faster '\n",
            " 'and more compact than other structured matrices used in the past. We also '\n",
            " 'introduce an efficient learning procedure for optimizing such matrices in a '\n",
            " 'data dependent fashion. We demonstrate the significant advantages of the '\n",
            " 'proposed approach in solving the approximate nearest neighbor (ANN) image '\n",
            " 'search problem with both binary embedding and quantization. We find that the '\n",
            " 'orthogonality plays a very important role in solving ANN problem, since the '\n",
            " 'random orthogonal Kronecker projection has already provided promising '\n",
            " 'performance. Comprehensive experiments show that the proposed approach can '\n",
            " 'achieve similar or better accuracy as the existing state-of-the-art but with '\n",
            " 'significantly less time and memory.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/2d33cbf5e62d0cbff5079b0ea0678892c4cc982e\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Image pattern discovery by using the spatial closeness of visual code words\n",
            "\n",
            "Abstract : \n",
            "('A graph regularized non-negative matrix factorization (NMF) model is '\n",
            " 'proposed for image pattern discovery. Each image is represented by its '\n",
            " 'histogram of visual words (i.e. bag-of-words) and the image contents are '\n",
            " 'discovered by the NMF model. The graph regularization preserves the spatial '\n",
            " 'closeness of visual code words in the obtained patterns, thus improving the '\n",
            " 'bag-of-words representation against its main shortcoming: the loss of '\n",
            " 'spatial information. Experiments on a subset of the Caltech256 database show '\n",
            " 'the efficacy of the proposed model.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/0ee30961f9fba57ba9c44e1465d979491a0e796d\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Subspace Projection Methods for Large Scale Image Data Analysis\n",
            "\n",
            "Abstract : \n",
            "('Images have become the most popular type of multimedia in the Big Data era. '\n",
            " 'Widely used applications like CBIR underscore the importance of image '\n",
            " 'understanding, especially in terms of semantically meaningful information. '\n",
            " 'Typically, high dimensional image descriptors are embedded to a subspace '\n",
            " 'using a simple linear projection. However, semantic information has a '\n",
            " 'complex distribution in feature space that requires a non-linear projection. '\n",
            " 'We first estimate an intrinsic dimensionality of image data. Next we build a '\n",
            " 'measure of visual information in embedded subspace. We compare several '\n",
            " 'linear and non-linear projection methods. We use multiple image databases '\n",
            " 'towards a comprehensive evaluation in terms of information content, '\n",
            " 'consequent recognition rates, and computational cost. This paper is relevant '\n",
            " 'for researchers interested in dimensionality reduction for large scale image '\n",
            " 'understanding that preserves semantically relevant information.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/63d19df502c4a9e42ca27842dc6606dde8a31d76\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Dimensionality reduction for image classification via mutual information maximization\n",
            "\n",
            "Abstract : \n",
            "('Low-level feature encoding combined with Spatial Pyramid Matching (SPM) is '\n",
            " 'widely adopted in the image classification system nowadays to extract '\n",
            " 'features, which are usually high-dimensional. This not only makes the '\n",
            " 'classification problem computationally prohibitive, but also raises other '\n",
            " 'issues, such as the “curse of dimensionality”. In this paper we present '\n",
            " 'supervised dimensionality reduction (DR) approaches that try to maximize the '\n",
            " 'mutual information (MI) between the class labels and the low-dimensional '\n",
            " 'features through an orthonormal linear projection. In addition to reduced '\n",
            " 'computational load, using the extracted low-dimensional features during '\n",
            " 'classification also leads to higher accuracies, as evident from a series of '\n",
            " 'image classification experiments in this paper.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/932d67d450e0541839a72e2f4228199ed08563e3\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Learning-based versus model-based log-polar feature extraction operators: a comparative study\n",
            "\n",
            "Abstract : \n",
            "('We compare two distinct primal sketch feature extraction operators: one '\n",
            " 'based on neural network feature learning and the other based on mathematical '\n",
            " 'models of the features. We tested both kinds of operator with a set of '\n",
            " 'known, but previously untrained, synthetic features and, while varying their '\n",
            " \"classification thresholds, measured the operator's false acceptance and \"\n",
            " 'false rejection errors. Results have shown that the model-based approach is '\n",
            " 'more unstable and unreliable than the learning-based approach, which '\n",
            " 'presented better results with respect to the number of correctly classified '\n",
            " 'features.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/3151038f3354a2af9634f092f5f33739668cafad\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Taming Wild High Dimensional Text Data with a Fuzzy Lash\n",
            "\n",
            "Abstract : \n",
            "('The bag of words (BOW) represents a corpus in a matrix whose elements are '\n",
            " 'the frequency of words. However, each row in the matrix is a very '\n",
            " 'high-dimensional sparse vector. Dimension reduction (DR) is a popular method '\n",
            " 'to address sparsity and high-dimensionality issues. Among different '\n",
            " 'strategies to develop DR method, Unsupervised Feature Transformation (UFT) '\n",
            " 'is a popular strategy to map all words on a new basis to represent BOW. The '\n",
            " 'recent increase of text data and its challenges imply that DR area still '\n",
            " 'needs new perspectives. Although a wide range of methods based on the UFT '\n",
            " 'strategy has been developed, the fuzzy approach has not been considered for '\n",
            " 'DR based on this strategy. This research investigates the application of '\n",
            " 'fuzzy clustering as a DR method based on the UFT strategy to collapse BOW '\n",
            " 'matrix to provide a lower-dimensional representation of documents instead of '\n",
            " 'the words in a corpus. The quantitative evaluation shows that fuzzy '\n",
            " 'clustering produces superior performance and features to Principal '\n",
            " 'Components Analysis (PCA) and Singular Value Decomposition (SVD), two '\n",
            " 'popular DR methods based on the UFT strategy.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/e69d6dd897fbcc466c611e122acbbf23c7404675\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Soft assignment vs hard assignment coding for bag of visual words\n",
            "\n",
            "Abstract : \n",
            "('In image classification and retrieval, the semantic gap is the major '\n",
            " 'challenge. It characterizes the difference between human perception of a '\n",
            " 'concept and how it can be represented using machine level language. Bag of '\n",
            " 'visual words is a well-known efficient method for image representation, '\n",
            " 'however it showed some limitations. The loss of information during the '\n",
            " 'vector quantization process is one of these limitations. Many approaches '\n",
            " 'were proposed in order to deal with this, such as the soft-assignment '\n",
            " 'technique and sparse or local coding schemes. This paper aims to compare and '\n",
            " 'evaluate the extent that has the soft-assignment approach especially the '\n",
            " 'recently proposed locality-constrained linear coding over the traditional '\n",
            " 'hard assignment methods.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/7c422ca3eeb678bb740c31f9f9de4611e7217268\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Discriminative Partition Sparsity Analysis\n",
            "\n",
            "Abstract : \n",
            "('Effective dimensionality reduction has been an attractive research area for '\n",
            " 'many large-scale vision and multimedia tasks. Several recent methods attempt '\n",
            " 'to learn optimized graph-based embedding for fast and accurate applications. '\n",
            " 'In this paper, we propose a novel linear unsupervised algorithm, termed '\n",
            " 'Discriminative Partition Sparsity Analysis (DPSA), explicitly considering '\n",
            " 'different probabilistic distributions that exist over the data points, '\n",
            " 'meanwhile preserving the natural locality relationship among the data. '\n",
            " 'Specifically, the Gaussian mixture model (GMM) is first applied to partition '\n",
            " 'all samples into several clusters. In each cluster, a number of sparse '\n",
            " 'sub-graphs are computed via the ℓ1-norm constraint to optimally represent '\n",
            " 'the intrinsic data structure. Such sub-graphs are demonstrated to be robust '\n",
            " 'to data noise, automatically sparse and adaptive to the neighborhood. All '\n",
            " 'the sub-graphs from the clusters are then combined into a whole '\n",
            " 'discriminative optimization framework for final reduction. We have '\n",
            " 'systematically evaluated our method on three image datasets: USPS digital '\n",
            " 'hand-writing, CMU PIE face and CIFAR-10 tiny image, showing its accurate and '\n",
            " 'robust performance for image classification.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/466b594b3d28b0bfa5b8347b55aab39d328eb8d9\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Scene image classification using locality-constrained linear coding based on histogram intersection\n",
            "\n",
            "Abstract : \n",
            "('Recently linear Spatial Pyramid Matching (SPM) method based on sparse coding '\n",
            " 'has achieved great success in image classification. The raise of '\n",
            " 'Locality-constrained Linear Coding (LLC) proves the importance of locality. '\n",
            " 'In this paper, we propose an improved feature coding scheme called '\n",
            " 'Locality-constrained Linear Coding Based on Histogram Intersection (HILLC). '\n",
            " 'HILLC uses histogram intersection to describe the distance between feature '\n",
            " 'vector and codebook. For each feature vector, search the KNN nearest '\n",
            " 'neighbors to construct a local codebook. Compared with LLC, HILLC can obtain '\n",
            " 'more robust codes. Experimental results demonstrate that our proposed method '\n",
            " 'outperforms other related coding methods.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/c6ac51ba7e269d4b6ad6a1772fba2039e1610d78\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Efficient Feature Extraction for Image Classification\n",
            "\n",
            "Abstract : \n",
            "('In many image classification applications, input feature space is often '\n",
            " 'high-dimensional and dimensionality reduction is necessary to alleviate the '\n",
            " 'curse of dimensionality or to reduce the cost of computation. In this paper, '\n",
            " 'we extract discriminant features for image classification by learning a '\n",
            " 'low-dimensional embedding from finite labeled samples. In the new feature '\n",
            " 'space, intra-class compactness and extra-class separability are achieved '\n",
            " 'simultaneously. Target dimensionality of the embedding is selected by '\n",
            " 'spectral analysis. Our method is designed suitable for data with both uni- '\n",
            " 'and multi-modal class distributions. We also develop its two-dimensional '\n",
            " 'variant which makes use of the matrix representation of images. Experimental '\n",
            " 'results on three real image datasets demonstrate the efficacy of our method '\n",
            " 'compared to the state of the art.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/337b4b34cdf643f35edca9de190e50296c5c5b15\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Transfer Sparse Coding for Robust Image Representation\n",
            "\n",
            "Abstract : \n",
            "('Sparse coding learns a set of basis functions such that each input signal '\n",
            " 'can be well approximated by a linear combination of just a few of the bases. '\n",
            " 'It has attracted increasing interest due to its state-of-the-art performance '\n",
            " 'in BoW based image representation. However, when labeled and unlabeled '\n",
            " 'images are sampled from different distributions, they may be quantized into '\n",
            " 'different visual words of the codebook and encoded with different '\n",
            " 'representations, which may severely degrade classification performance. In '\n",
            " 'this paper, we propose a Transfer Sparse Coding (TSC) approach to construct '\n",
            " 'robust sparse representations for classifying cross-distribution images '\n",
            " 'accurately. Specifically, we aim to minimize the distribution divergence '\n",
            " 'between the labeled and unlabeled images, and incorporate this criterion '\n",
            " 'into the objective function of sparse coding to make the new representations '\n",
            " 'robust to the distribution difference. Experiments show that TSC can '\n",
            " 'significantly outperform state-of-the-art methods on three types of computer '\n",
            " 'vision datasets.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/afe14b9034f71c7078cd03626853170ef51b8060\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Feature representation based on intrinsic structure discovery in high dimensional space\n",
            "\n",
            "Abstract : \n",
            "('In this paper, an image is regarded as a collection of image patches that '\n",
            " 'can be referred to as points with certain intrinsic structures/patterns in '\n",
            " 'high-dimensional space. These structures contain vital information of image '\n",
            " 'features and thus provide a novel method for image feature representation. '\n",
            " 'To discover these intrinsic structures, we first propose neighborhood linear '\n",
            " 'embedding (NLE), an unsupervised learning algorithm, to discover '\n",
            " 'neighborhood relationship and global distribution of input data '\n",
            " 'simultaneously. Secondly, NLE is extended to discover the clustering '\n",
            " 'structure of data by incorporating with a Euclidean distance histogram and a '\n",
            " 'series of band pass filters. Finally, by combining with a dimensionality '\n",
            " 'reduction technique, the discovered intrinsic structures are visualized and '\n",
            " 'manipulated in low-dimensional space in the format known as embeddings. The '\n",
            " 'proposed NLE allows the discovery process to adapt to the characteristics of '\n",
            " 'input data. In addition, it is revealed that an image feature composed of '\n",
            " 'image patches can be tracked by tracking the contour containing embeddings '\n",
            " 'of the corresponding image patches')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/bd6913d08ced924713e43239ab7484468bd7a18d\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Feature-Based Sparse Representation for Image Similarity Assessment\n",
            "\n",
            "Abstract : \n",
            "('Assessment of image similarity is fundamentally important to numerous '\n",
            " 'multimedia applications. The goal of similarity assessment is to '\n",
            " 'automatically assess the similarities among images in a perceptually '\n",
            " 'consistent manner. In this paper, we interpret the image similarity '\n",
            " 'assessment problem as an information fidelity problem. More specifically, we '\n",
            " 'propose a feature-based approach to quantify the information that is present '\n",
            " 'in a reference image and how much of this information can be extracted from '\n",
            " 'a test image to assess the similarity between the two images. Here, we '\n",
            " 'extract the feature points and their descriptors from an image, followed by '\n",
            " 'learning the dictionary/basis for the descriptors in order to interpret the '\n",
            " 'information present in this image. Then, we formulate the problem of the '\n",
            " 'image similarity assessment in terms of sparse representation. To evaluate '\n",
            " 'the applicability of the proposed feature-based sparse representation for '\n",
            " 'image similarity assessment (FSRISA) technique, we apply FSRISA to three '\n",
            " 'popular applications, namely, image copy detection, retrieval, and '\n",
            " 'recognition by properly formulating them to sparse representation problems. '\n",
            " 'Promising results have been obtained through simulations conducted on '\n",
            " 'several public datasets, including the Stirmark benchmark, Corel-1000, '\n",
            " 'COIL-20, COIL-100, and Caltech-101 datasets.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/eb83f2cbe07db1ef179295c1cdaadcf73d99b9ab\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Local patch effects on LPP and DLA in dimensionality reduction\n",
            "\n",
            "Abstract : \n",
            "('In order to preserve the local structure of the input data, many '\n",
            " 'dimensionality reduction algorithms are involved in the definition of '\n",
            " 'certain locality in the feature space. Thus local patch selection will '\n",
            " 'directly affect the performance of these algorithms. In this paper, we '\n",
            " 'propose a new method of local patch selection for dimensionality reduction. '\n",
            " 'Specially, we incorporate our method into locality-preserving projection '\n",
            " '(LPP) and discriminative locality alignment (DLA), which are two typical '\n",
            " 'algorithms without and with using label information in local patch '\n",
            " 'selection. We do the experiments for scene classification with the Object '\n",
            " 'Bank of 2124 original dimensions. We provide comprehensive evaluation of '\n",
            " 'patch selection methods and extensive analysis on the performance of '\n",
            " 'different methods.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/a02dcc8a98b4deea073364ac1e1cdea782532a88\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Document Specific Sparse Coding for Word Retrieval\n",
            "\n",
            "Abstract : \n",
            "('Bag of words (BoW) based retrieval is an efficient method to compare the '\n",
            " 'visual similarity between two images. Recognition free methods based on BoW '\n",
            " 'have shown to outperform OCR based methods. We further improve the '\n",
            " 'performance by defining a document specific sparse coding scheme for '\n",
            " 'representing visual words (interest points) in document images. Our method '\n",
            " 'is motivated by the successful use of sparsity in signal representation by '\n",
            " 'exploiting the neighbourhood properties. In addition to providing insights '\n",
            " 'into the design of the coding scheme, we also verify the method on two data '\n",
            " 'sets and compare with the recent methods. We have also developed text query '\n",
            " 'based search solution, and we report performance comparable to image based '\n",
            " 'search.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/b71cfd2d8cbf9d45e436d03f7b3583ead3b9e58c\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  An effective object recognition system by a mobile application\n",
            "\n",
            "Abstract : \n",
            "('Unparalleled growth in the sharing of media via networks has prompted a '\n",
            " 'great deal of research into issues pertaining to image retrieval. The '\n",
            " 'training and verification of image retrieval systems requires a large number '\n",
            " 'of labelled images with ground truth; however, most researchers employ '\n",
            " 'synthetic datasets for their experiments. In this study, we developed a '\n",
            " 'system based on a mobile phone App for the collection of information '\n",
            " 'pertaining to the location of objects in images. The proposed system is '\n",
            " 'simple and easy to use. Experiments demonstrate the excellent performance of '\n",
            " 'the proposed system with regard to accuracy and response time. This study '\n",
            " 'demonstrates the feasibility of collecting image information using mobile '\n",
            " 'phones.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/5cb08503f44f8e0aaeb7bd18faaba71022b8934a\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Learning to Combine Ad-hoc Ranking Functions for Image Retrieval\n",
            "\n",
            "Abstract : \n",
            "('Along with the success of \"bag of visual words\" scheme in content based '\n",
            " 'image retrieval (CBIR), various technologies in text information retrieval '\n",
            " 'realm have been transferred into image retrieval system and obtain promising '\n",
            " 'performance. However, how to select the suitable ranking technology, such as '\n",
            " 'ranking model, for a specific image database is still an open question. '\n",
            " 'Because most ranking models are data-dependent, it is hard to find an '\n",
            " 'optimal model for all the applications. In this paper, we propose to resolve '\n",
            " 'this problem for CBIR with the learning to rank approach which has been '\n",
            " 'widely utilized in text retrieval. Specifically, we consider several well '\n",
            " 'performed ad-hoc ranking models and use their ranking scores to construct '\n",
            " 'the ranking features for the Ranking SVM framework. To best preserve the '\n",
            " 'spatial structures existed in the visual words of image, we split the image '\n",
            " 'into different size blocks, and design the ranking features with a pyramid '\n",
            " 'approach from large blocks to small blocks. Experimental results on both '\n",
            " 'Oxford and Image Net databases demonstrate the effectiveness of proposed '\n",
            " 'method compared with the performance that individual ranking model is '\n",
            " 'adopted. Moreover, the proposed method brings little computational burden to '\n",
            " 'the system and the efficiency analysis proves its scalability.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/b861f715776aacf31e6b0a3bdbda54dda1195f51\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Hash functions for near duplicate image retrieval\n",
            "\n",
            "Abstract : \n",
            "('This paper proposes new hash functions for indexing local image descriptors. '\n",
            " 'These functions are first applied and evaluated as a range neighbor '\n",
            " 'algorithm. We show that it obtains similar results as several state of the '\n",
            " 'art algorithms. In the context of near duplicate image retrieval, we '\n",
            " 'integrated the proposed hash functions within a bag of words approach. '\n",
            " 'Because most of the other methods use a kmeans-based vocabulary, they '\n",
            " 'require an off-line learning stage and highest performance is obtained when '\n",
            " 'the vocabulary is learned on the searched database. For application where '\n",
            " 'images are often added or removed from the searched dataset, the learning '\n",
            " 'stage must be repeated regularly in order to keep high recalls. We show that '\n",
            " 'our hash functions in a bag of words approach has similar recalls as bag of '\n",
            " 'words with kmeans vocabulary learned on the searched dataset, but our method '\n",
            " 'does not require any learning stage. It is thus very well adapted to near '\n",
            " 'duplicate image retrieval applications where the dataset evolves regularly '\n",
            " 'as there is no need to update the vocabulary to guarantee the best '\n",
            " 'performance.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/3e0a995d79dd6de7ee1f6bc736934e266f5db2f2\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Object retrieval with large vocabularies and fast spatial matching\n",
            "\n",
            "Abstract : \n",
            "('In this paper, we present a large-scale object retrieval system. The user '\n",
            " 'supplies a query object by selecting a region of a query image, and the '\n",
            " 'system returns a ranked list of images that contain the same object, '\n",
            " 'retrieved from a large corpus. We demonstrate the scalability and '\n",
            " 'performance of our system on a dataset of over 1 million images crawled from '\n",
            " 'the photo-sharing site, Flickr [3], using Oxford landmarks as queries. '\n",
            " 'Building an image-feature vocabulary is a major time and performance '\n",
            " 'bottleneck, due to the size of our dataset. To address this problem we '\n",
            " 'compare different scalable methods for building a vocabulary and introduce a '\n",
            " 'novel quantization method based on randomized trees which we show '\n",
            " 'outperforms the current state-of-the-art on an extensive ground-truth. Our '\n",
            " 'experiments show that the quantization has a major effect on retrieval '\n",
            " 'quality. To further improve query performance, we add an efficient spatial '\n",
            " 'verification stage to re-rank the results returned from our bag-of-words '\n",
            " 'model and show that this consistently improves search quality, though by '\n",
            " 'less of a margin when the visual vocabulary is large. We view this work as a '\n",
            " 'promising step towards much larger, \"web-scale \" image corpora.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/28e4b8ebbdb0e80f03b6f0578deeb38694af081e\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Logo Spotting by a Bag-of-words Approach for Document Categorization\n",
            "\n",
            "Abstract : \n",
            "('In this paper we present a method for document categorization which '\n",
            " 'processes incoming document images such as invoices or receipts. The '\n",
            " 'categorization of these document images is done in terms of the presence of '\n",
            " 'a certain graphical logo detected without segmentation. The graphical logos '\n",
            " 'are described by a set of local features and the categorization of the '\n",
            " 'documents is performed by the use of a bag-of-words model. Spatial coherence '\n",
            " 'rules are added to reinforce the correct category hypothesis, aiming also to '\n",
            " 'spot the logo inside the document image. Experiments which demonstrate the '\n",
            " 'effectiveness of this system on a large set of real data are presented.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/8c99f92e9256d6bd7f0301bf7737b01f314508be\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Bregman Divergence-Based Regularization for Transfer Subspace Learning\n",
            "\n",
            "Abstract : \n",
            "('The regularization principals [31] lead approximation schemes to deal with '\n",
            " 'various learning problems, e.g., the regularization of the norm in a '\n",
            " 'reproducing kernel Hilbert space for the ill-posed problem. In this paper, '\n",
            " 'we present a family of subspace learning algorithms based on a new form of '\n",
            " 'regularization, which transfers the knowledge gained in training samples to '\n",
            " 'testing samples. In particular, the new regularization minimizes the Bregman '\n",
            " 'divergence between the distribution of training samples and that of testing '\n",
            " 'samples in the selected subspace, so it boosts the performance when training '\n",
            " 'and testing samples are not independent and identically distributed. To test '\n",
            " 'the effectiveness of the proposed regularization, we introduce it to popular '\n",
            " 'subspace learning algorithms, e.g., principal components analysis (PCA) for '\n",
            " \"cross-domain face modeling; and Fisher's linear discriminant analysis \"\n",
            " \"(FLDA), locality preserving projections (LPP), marginal Fisher's analysis \"\n",
            " '(MFA), and discriminative locality alignment (DLA) for cross-domain face '\n",
            " 'recognition and text categorization. Finally, we present experimental '\n",
            " 'evidence on both face image data sets and text data sets, suggesting that '\n",
            " 'the proposed Bregman divergence-based regularization is effective to deal '\n",
            " 'with cross-domain learning problems.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/4118b4fc7d61068b9b448fd499876d139baeec81\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Deep feature hash codes framework for content-based image retrieval\n",
            "\n",
            "Abstract : \n",
            "('For large-scale image retrieval, high dimensional features make the '\n",
            " 'retrieval system inefficiency. In this paper, we propose a framework of deep '\n",
            " 'feature hash codes for content-based image retrieval system. In this '\n",
            " 'framework, we firstly extract image features by a pre-trained convolutional '\n",
            " 'neural networks model. Secondly, we use different hashing methods for binary '\n",
            " 'feature extraction. Finally, we use the best binary encoding features to '\n",
            " 'build a content-based image retrieval system. The experimental results '\n",
            " 'demonstrate that with the decrease of feature dimension, our method not only '\n",
            " 'does not reduce the retrieval precision, but also can improve the retrieval '\n",
            " 'accuracy in some cases. The retrieval accuracy of 256 bits binary features '\n",
            " 'can surpass the traditional method of 256 dimensional (4096 bits) features. '\n",
            " 'Once the feature bits are 16 times lower, the storage space will decrease 16 '\n",
            " 'times and the retrieval efficiency will be greatly increased. Therefore, our '\n",
            " 'method can effectively improve the speed and precision of content-based '\n",
            " 'image retrieval system.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/6c7f8afb2b32d9b50d5f4bdfd243f4bdc4e5057e\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Large-scale image retrieval with compressed Fisher vectors\n",
            "\n",
            "Abstract : \n",
            "('The problem of large-scale image search has been traditionally addressed '\n",
            " 'with the bag-of-visual-words (BOV). In this article, we propose to use as an '\n",
            " 'alternative the Fisher kernel framework. We first show why the Fisher '\n",
            " 'representation is well-suited to the retrieval problem: it describes an '\n",
            " 'image by what makes it different from other images. One drawback of the '\n",
            " 'Fisher vector is that it is high-dimensional and, as opposed to the BOV, it '\n",
            " 'is dense. The resulting memory and computational costs do not make Fisher '\n",
            " 'vectors directly amenable to large-scale retrieval. Therefore, we compress '\n",
            " 'Fisher vectors to reduce their memory footprint and speed-up the retrieval. '\n",
            " 'We compare three binarization approaches: a simple approach devised for this '\n",
            " 'representation and two standard compression techniques. We show on two '\n",
            " 'publicly available datasets that compressed Fisher vectors perform very well '\n",
            " 'using as little as a few hundreds of bits per image, and significantly '\n",
            " 'better than a very recent compressed BOV approach.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/48257a889a9aa61998ae20fa52b25d90c441f63a\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Accelerated recognition of handwritten Urdu digits using Shape Context based gradual pruning\n",
            "\n",
            "Abstract : \n",
            "('Prototype based object recognition requires measuring similarities between '\n",
            " 'the test object and the prototype categories. When multiple instances per '\n",
            " 'object are stored in the prototype set, this task becomes computationally '\n",
            " 'expensive. To increase the efficiency, pruning techniques are used. In this '\n",
            " 'work we have presented a gradual pruning approach based on the '\n",
            " 'dissimilarities between the test object and the objects in the prototype '\n",
            " 'set. A mathematical expression has been derived analytically for the savings '\n",
            " 'in computational time. This approach is applied to the task of hand written '\n",
            " 'Urdu digit recognition using Shape Context. Compared to the classical '\n",
            " '(non-pruned) and step pruning approaches, our gradual pruning based method '\n",
            " 'is found to be faster without compromise on accuracy.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/98661a97e58af5b0f9bda20fd7a4f272804507e6\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  A novel duplicate images detection method based on PLSA model\n",
            "\n",
            "Abstract : \n",
            "('Web image search results usually contain duplicate copies. This paper '\n",
            " 'considers the problem of detecting and \\n'\n",
            " 'clustering duplicate images contained in web image search results. Detecting '\n",
            " 'and clustering the duplicate images together \\n'\n",
            " \"facilitates users' viewing. A novel method is presented in this paper to \"\n",
            " 'detect and cluster duplicate images by measuring \\n'\n",
            " 'similarity between their topics. More specifically, images are viewed as '\n",
            " 'documents consisting of visual words formed by \\n'\n",
            " 'vector quantizing the affine invariant visual features. Then a statistical '\n",
            " 'model widely used in text domain, the \\n'\n",
            " 'PLSA(Probabilistic Latent Semantic Analysis) model, is utilized to map '\n",
            " 'images into a probabilistic latent semantic space. \\n'\n",
            " 'Because the main content remains unchanged despite small digital alteration, '\n",
            " 'duplicate images will be close to each other \\n'\n",
            " 'in the derived semantic space. Based on this, a simple clustering process '\n",
            " 'can successfully detect duplicate images and \\n'\n",
            " 'cluster them together. Comparing to those methods based on comparison '\n",
            " 'between hash value of visual words, this method \\n'\n",
            " 'is more robust to the visual feature level alteration posed on the images. '\n",
            " 'Experiments demonstrates the effectiveness of this \\n'\n",
            " 'method.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/f7339223dd8b9516a56b5537908d3150010eb89b\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Patch Alignment for Dimensionality Reduction\n",
            "\n",
            "Abstract : \n",
            "('Spectral analysis-based dimensionality reduction algorithms are important '\n",
            " 'and have been popularly applied in data mining and computer vision '\n",
            " 'applications. To date many algorithms have been developed, e.g., principal '\n",
            " 'component analysis, locally linear embedding, Laplacian eigenmaps, and local '\n",
            " 'tangent space alignment. All of these algorithms have been designed '\n",
            " 'intuitively and pragmatically, i.e., on the basis of the experience and '\n",
            " 'knowledge of experts for their own purposes. Therefore, it will be more '\n",
            " 'informative to provide a systematic framework for understanding the common '\n",
            " 'properties and intrinsic difference in different algorithms. In this paper, '\n",
            " 'we propose such a framework, named \"patch alignment,rdquo which consists of '\n",
            " 'two stages: part optimization and whole alignment. The framework reveals '\n",
            " 'that (1) algorithms are intrinsically different in the patch optimization '\n",
            " 'stage and (2) all algorithms share an almost identical whole alignment '\n",
            " 'stage. As an application of this framework, we develop a new dimensionality '\n",
            " 'reduction algorithm, termed discriminative locality alignment (DLA), by '\n",
            " 'imposing discriminative information in the part optimization stage. DLA can '\n",
            " '(1) attack the distribution nonlinearity of measurements; (2) preserve the '\n",
            " 'discriminative ability; and (3) avoid the small-sample-size problem. '\n",
            " 'Thorough empirical studies demonstrate the effectiveness of DLA compared '\n",
            " 'with representative dimensionality reduction algorithms.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/2677672ec54530e8911a758de2688bd80e1ade96\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Find dominant bins of a histogram by sparse representation\n",
            "\n",
            "Abstract : \n",
            "('Bag of words (BoW) method has been widely used for image (feature) '\n",
            " 'representation and gained great success for its simplicity but efficient '\n",
            " 'power. However, due to the unsupervised clustering, visual words are equally '\n",
            " 'treated for all classes and are not discriminative for classification. We '\n",
            " 'found that only a few words are activated when samples from one class are '\n",
            " 'sparsely represented over the visual words. Based on this observation, we '\n",
            " 'propose an approach to find the dominant and useful bins in image histogram '\n",
            " 'for each class with sparse representation technique. The resulted histogram '\n",
            " 'with only dominant bins then becomes more discriminative for classification. '\n",
            " 'Experiments on three widely used datasets demonstrate superior performance '\n",
            " 'of the proposed approach over standard BoW method.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/3e358f0c0241299b69aab0f40a2359dacc439de3\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Weighted sparse representation using a learned distance metric for face recognition\n",
            "\n",
            "Abstract : \n",
            "('This paper presents a novel weighted sparse representation classification '\n",
            " 'for face recognition with a learned distance metric (WSRC-LDM) which learns '\n",
            " 'a Mahalanobis distance to calculate the weight and code the testing face. '\n",
            " 'The Mahalanobis distance is learned by using the information-theoretic '\n",
            " 'metric learning (ITML) which helps to define a better weight used in WSRC. '\n",
            " 'In the meantime, the learned distance metric takes advantage of the '\n",
            " 'classification rule of SRC which helps the proposed method classify more '\n",
            " 'accurately. Extensive experiments verify the effectiveness of the proposed '\n",
            " 'method.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/ce8db0fe11e7c96d08de561506f9f8f399dabbb2\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  A Practical Approach to Motion Estimation for Omnidirectional Vision\n",
            "\n",
            "Abstract : \n",
            "('Compared with conventional perspective camera, data noise for '\n",
            " 'omnidirectional camera is more serious due to its non-linear projection. For '\n",
            " 'linear estimation of motion parameters with noise corrupted data, it is '\n",
            " 'necessary to establish sufficient number of correspondences and use a '\n",
            " 'appropriate robust tech- nique. In this paper, our interests concentrate on '\n",
            " 'two parts. First, we propose a new method to establish a large number of '\n",
            " 'reliable point correspondences between omnidirectional images. Classical '\n",
            " 'affine invariant region detecting and matching algorithms are initially '\n",
            " 'employed, then more distinctive point correspondences inside or near the '\n",
            " 'matched regions are extended. Our second work focuses on the RANSAC based '\n",
            " 'linear estimation technique. Based on the simulation experiment we give a '\n",
            " 'strategy to grad- ually select more and more inliers from a noise-corrupted '\n",
            " 'data set, by which the initial guess of motion parameters improved in '\n",
            " 'precision and stability. Experiment results with true data show that our '\n",
            " 'method works well in real applications and makes the performance of linear '\n",
            " 'estimates of motion parameters improved greatly.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/48787e67d7708a23763cc3f9586f62dd056c794d\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Image Retrieval with a Visual Thesaurus\n",
            "\n",
            "Abstract : \n",
            "('Current state-of-art of image retrieval methods represent images as an '\n",
            " 'unordered collection of local patches, each of which is classified as a '\n",
            " '\"visual word\" from a fixed vocabulary. This paper presents a simple but '\n",
            " 'innovative way to uncover the spatial relationship between visual words so '\n",
            " 'that we can discover words that represent the same latent topic and thereby '\n",
            " 'improve the retrieval results. The method in this paper is borrowed from '\n",
            " 'text retrieval, and is analogous to a text thesaurus in that it describes a '\n",
            " 'broad set of equivalence relationship between words. We evaluate our method '\n",
            " 'on the popular Oxford Building dataset. This makes it possible to compare '\n",
            " 'our method with previous work on image retrieval, and the results show that '\n",
            " 'our method is comparable to more complex state of the art methods.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/158ad930d71cf72539deb1baeeca21dcc85393a9\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  A location-aware scale-space method for salient object detection\n",
            "\n",
            "Abstract : \n",
            "('Many existing saliency detection methods made an assumption that the salient '\n",
            " 'object is on the center of the image and incorporated such center-biased '\n",
            " 'assumption in the design of their algorithms. Obviously, this is not always '\n",
            " 'proper to set, especially for those imageries acquired by unmanned '\n",
            " 'monitoring system or device (e.g., surveillance camera), in which the '\n",
            " 'salient object could appear in any location within the image. Consequently, '\n",
            " 'the resulted saliency detection performance could be greatly degraded. In '\n",
            " 'this paper, an existing hypercomplex Fourier transform (HFT) based saliency '\n",
            " 'detection algorithm is investigated and modified for improving the saliency '\n",
            " 'detection performance. In details, we remove its prior assumption on `center '\n",
            " \"bias' and exploit a location-aware strategy to identify the optimal saliency \"\n",
            " 'map across multiple scales of the image. Extensive simulation results have '\n",
            " 'justified that the proposed location-aware HFT-based approach clearly '\n",
            " 'outperforms existing five state-of-the-art algorithms on saliency detection.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/57a6757238874d0f7a12e58b8fc3bec724e00799\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  A Comprehensive Study Over VLAD and Product Quantization in Large-Scale Image Retrieval\n",
            "\n",
            "Abstract : \n",
            "('This paper deals with content-based large-scale image retrieval using the '\n",
            " 'state-of-the-art framework of VLAD and Product Quantization proposed by '\n",
            " 'Jegou as a starting point. Demonstrating an excellent accuracy-efficiency '\n",
            " 'trade-off, this framework has attracted increased attention from the '\n",
            " 'community and numerous extensions have been proposed. In this work, we make '\n",
            " 'an in-depth analysis of the framework that aims at increasing our '\n",
            " 'understanding of its different processing steps and boosting its overall '\n",
            " 'performance. Our analysis involves the evaluation of numerous extensions '\n",
            " '(both existing and novel) as well as the study of the effects of several '\n",
            " 'unexplored parameters. We specifically focus on: a) employing more efficient '\n",
            " 'and discriminative local features; b) improving the quality of the '\n",
            " 'aggregated representation; and c) optimizing the indexing scheme. Our '\n",
            " 'thorough experimental evaluation provides new insights into extensions that '\n",
            " 'consistently contribute, and others that do not, to performance improvement, '\n",
            " 'and sheds light onto the effects of previously unexplored parameters of the '\n",
            " 'framework. As a result, we develop an enhanced framework that significantly '\n",
            " 'outperforms the previous best reported accuracy results on standard '\n",
            " 'benchmarks and is more efficient.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/f389e66bcc210d50bc5ea8f90f851e1f3e281354\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Dog breed classification via landmarks\n",
            "\n",
            "Abstract : \n",
            "('Object recognition is an important problem with a wide range of '\n",
            " 'applications. It is also a challenging problem, especially for animal '\n",
            " 'categorization as the differences among breeds can be subtle. In this paper, '\n",
            " 'based on statistical techniques for landmark-based shape representation, we '\n",
            " 'propose to model the shape of dog breed as points on the Grassmann manifold. '\n",
            " 'We consider the dog breed categorization as the classification problem on '\n",
            " 'this manifold. The proposed scheme is tested on a dataset including 8,351 '\n",
            " 'images of 133 different breeds. Experimental results demonstrate the '\n",
            " 'advocated scheme outperforms state of the art approaches by nearly 20%.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/a2af07176a38fe844b0e2fdf4abae65472628b38\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Human shape recognition using radon transform and regularized principal component\n",
            "\n",
            "Abstract : \n",
            "('The aim of this study is to investigate the potential of Radon Transform and '\n",
            " 'Regularized Principal Component Analysis as feature extraction for '\n",
            " 'classification of human and non human. Several training algorithms are used '\n",
            " 'for the neural network. The finding of the investigation shows that the best '\n",
            " 'training algorithm is Lavenberg-Marquardt (LM). In addition, the execution '\n",
            " 'time taken by LM is fastest among the training.The outcomes of the proposed '\n",
            " 'method using LM are 0% False Rejection Rate (FRR) and 0% False Acceptance '\n",
            " 'Rate (FAR)ona database of 100 images on each category.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/8161b85a9d4593bc58f225a3aa29eb9e3f59f652\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Indexing of the CNN features for the large scale image search\n",
            "\n",
            "Abstract : \n",
            "('The convolutional neural network (CNN) features can give good description of '\n",
            " 'image content, which usually represent an image with a single feature '\n",
            " 'vector. Although CNN features are more compact than local descriptors, they '\n",
            " 'still cannot efficiently deal with large-scale retrieval due to the linearly '\n",
            " 'incremental cost of computation and storage. To address this issue, we build '\n",
            " 'a simple but effective indexing framework on inverted table, which '\n",
            " 'significantly decreases both search time and memory usage. First, several '\n",
            " 'strategies are fully investigated to adapt inverted table to CNN features '\n",
            " 'for compensating for quantization error. We use multiple assignment for the '\n",
            " 'query and database images to increase the probability that relevant images '\n",
            " 'are assigned to the same visual word obtained via clustering. Embedding '\n",
            " 'codes are also introduced to improve retrieval accuracy by removing false '\n",
            " 'matches. Second, a novel indexing framework that combines inverted table and '\n",
            " 'hashing codes is proposed. This framework is faster than the reformed '\n",
            " 'inverted tables with the introduced strategies. Experiment on several '\n",
            " 'benchmark datasets demonstrates that our method yields faster retrieval '\n",
            " 'speed compared to brute-force search. We also provide fair comparison '\n",
            " 'between popular CNN features.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/42d087a0e2082b7f972740dc1a16bcfc856ae781\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  A novel trouble of moving EMU detection algorithm based on contextual semantic information\n",
            "\n",
            "Abstract : \n",
            "(\"It is essential to detect the state of EMU's component while running, since \"\n",
            " 'any small and subtle failure may cause major accidents in high-speed '\n",
            " 'running. The traditional detection approach adopts the image matching '\n",
            " 'technology, which suffers from the problem when the two images dislocation. '\n",
            " 'The drawback stems from the image matching approach based on the visual '\n",
            " 'features only easily affected by the image quality and transformation. To '\n",
            " 'overcome this defect, this paper introduces the contextual semantic '\n",
            " 'information into image matching technology to detect the trouble of moving '\n",
            " 'EMU. There are two areas of novelty: first, the useful contextual semantic '\n",
            " 'constrained information is obtained by Conditional Random Fields model '\n",
            " 'instead of by manually labeled. And then we combine the feature appearance '\n",
            " 'similarity and contextual semantic information together in order to match '\n",
            " 'more accurate. The experimental result has shown that the proposed algorithm '\n",
            " 'can detect the trouble of moving EMU effectively, even in the circumstance '\n",
            " 'with low image quality, uncontrollable light and bright.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/02519185c0aae34c04d9568a3e222e8a8da1168b\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  The EMC analyzing and optimizing with highfrequency interference in PCB design\n",
            "\n",
            "Abstract : \n",
            "('In this paper, we make use of the software Ansoft Designer to analyze the '\n",
            " 'high-frequency interference in the PCB, and get the current plots & '\n",
            " \"EM(electric & magnetic) near field plots to see the effect on the PCB's EMC \"\n",
            " 'by the high-frequency interference. According to the current plots & EM near '\n",
            " 'field plots, we can analyze the EMC of the PCB and optimize the layout '\n",
            " 'design.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/8b318bad2997c5f8b6f1016df26b68053d49e8e8\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  On the burstiness of visual elements\n",
            "\n",
            "Abstract : \n",
            "('Burstiness, a phenomenon initially observed in text retrieval, is the '\n",
            " 'property that a given visual element appears more times in an image than a '\n",
            " 'statistically independent model would predict. In the context of image '\n",
            " 'search, burstiness corrupts the visual similarity measure, i.e., the scores '\n",
            " 'used to rank the images. In this paper, we propose a strategy to handle '\n",
            " 'visual bursts for bag-of-features based image search systems. Experimental '\n",
            " 'results on three reference datasets show that our method significantly and '\n",
            " 'consistently outperforms the state of the art.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/378238376d5011963309eb9eeffa8d09f0b18d49\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Methods to obtain the waveform profile from slope measurements\n",
            "\n",
            "Abstract : \n",
            "('There are many optical metrological techniques to determine the profile of a '\n",
            " 'surface or a wave-front. A group of them \\n'\n",
            " 'are based on the measurements of the profile slopes, like deflectometry or '\n",
            " 'wave-front sensors. In both sensors, the profile \\n'\n",
            " 'is then obtained by integrating the gradient information provided by the '\n",
            " 'measurements. The used integration method \\n'\n",
            " 'influences the quality of the obtained results. In this work we compare the '\n",
            " 'performance of different bi-dimensional \\n'\n",
            " 'integration methods to obtain the profile from the slopes, and we propose '\n",
            " 'some new methods. The first kind of methods \\n'\n",
            " 'is based on a path integral, in which the profile in a given point (x,y) is '\n",
            " 'obtained by a 1D integral from (0,0) to (x,0) \\n'\n",
            " 'followed by a 1D integral from (x,0) to (x,y). The second kind of methods is '\n",
            " 'based on finite differences, where the \\n'\n",
            " 'profile in a point is related with the profile in the neighbor points and '\n",
            " 'the slopes of those points. On these methods \\n'\n",
            " 'different interpolations can be used. Finally, the third kind of methods is '\n",
            " 'based on Fourier domain integration. \\n'\n",
            " 'Several simulation results are obtained to study the influence of several '\n",
            " 'parameters: spatial frequency of the signal, local \\n'\n",
            " 'slope errors, random noise, and edge effects. Fourier domain methods could '\n",
            " 'be considered as the gold standard, they \\n'\n",
            " 'suffer from edge effects because the signals are not periodic. Moreover they '\n",
            " 'can only be applied when regular Cartesian \\n'\n",
            " 'sampling is used. Path integral methods create artifacts along the '\n",
            " 'integration paths, when local errors are present. Finite \\n'\n",
            " 'difference methods are more versatile, and their accuracy depends on the '\n",
            " 'used interpolation methods.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/3d9faa8219027497e391c573bb606c7d99cf5749\n",
            "---\n",
            "-------\n",
            "---------------\n",
            "-------\n",
            "---\n",
            "Title:  Intelligent adaptive object recognition\n",
            "\n",
            "Abstract : \n",
            "('This research proposes an object recognition system using image processing '\n",
            " 'and neural network based classification. The system is capable of '\n",
            " 'recognizing 7 objects from an uncluttered background by extracting color, '\n",
            " 'texture and shape features. The proposed system consists of image '\n",
            " 'segmentation, feature extraction and classification. Diverse neural network '\n",
            " 'topology settings have been employed for evaluation. Experimental results '\n",
            " 'indicate that the proposed system achieves high accuracy 98% accurate for '\n",
            " 'real-time object recognition tasks.')\n",
            "\n",
            "Link: https://www.semanticscholar.org/paper/058130c35eb08d92725b13f050597eec93ed2bba\n",
            "---\n",
            "-------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiNISoSa2xXf",
        "colab_type": "text"
      },
      "source": [
        "## If you have any additional feedback about a query, or just feedback in general, we would very much appreciate it. The feedback will help in the qualitative analysis of our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJcKvcK4zL6G",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Feedback about a particular query\n",
        "\n",
        "%%capture\n",
        "\n",
        "query = \"The effect of negative sampling on embedding quality. noise contrastive sampling in vector representation. \" #@param {type:\"string\"}\n",
        "\n",
        "feedback = \"First result didn't seem to say anything about negative sampling\" #@param {type:\"string\"}\n",
        "\n",
        "values_list = worksheet2.col_values(3)\n",
        "values_list2 = worksheet2.col_values(4)\n",
        "rowV = max(len(values_list) , len(values_list2) )\n",
        "worksheet2.update_cell(rowV+1, 3, query)\n",
        "worksheet2.update_cell(rowV+1, 4, feedback)\n",
        "\n",
        "print('Submitted')\n",
        "print('Query recorded, ', query)\n",
        "print('Feedback recorded, ', feedback)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc3PMILi2LN6",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Genderal feedback\n",
        "\n",
        "%%capture\n",
        "\n",
        "feedback = \"UI could use some work\" #@param {type:\"string\"}\n",
        "\n",
        "values_list = worksheet3.col_values(3)\n",
        "values_list2 = worksheet3.col_values(4)\n",
        "rowV = max(len(values_list) , len(values_list2) )\n",
        "worksheet3.update_cell(rowV+1, 3, feedback)\n",
        "\n",
        "print('Submitted')\n",
        "print('Feedback recorded, ', feedback)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}