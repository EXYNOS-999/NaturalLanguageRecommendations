{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "TpuIndex_build_index_and_search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santosh-Gupta/NaturalLanguageRecommendations/blob/master/notebooks/inference/TpuIndex_build_index_and_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf93M9RFhUj2",
        "colab_type": "text"
      },
      "source": [
        "### Inference with TPU-Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAul5EX_MMsm",
        "colab_type": "text"
      },
      "source": [
        "Download and install libraries, models, data, etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8wAw2JV6F4Am",
        "outputId": "1eebdf31-59b7-4b24-b50b-014b51fb5a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        }
      },
      "source": [
        "!gdown --id \"10LV9QbZOkUyOzR4nh8hxesoKJhpmvpM9\"   # citation vectors\n",
        "!gdown --id \"1-23aNm7j0bnycvyd_OaQfofVYPTewgOI\"   # abstract vectors\n",
        "!gdown --id \"1NyUQwgUNj9bFsiCnZ2TfKmWn5r-Y6wav\"   # TitlesIdAbstractsEmbedIds\n",
        "!wget 'https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar'\n",
        "!tar -xvf 'scibert_scivocab_uncased.tar'\n",
        "\n",
        "!pip install transformers --quiet\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import psutil\n",
        "import gc\n",
        "\n",
        "print('TensorFlow:', tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10LV9QbZOkUyOzR4nh8hxesoKJhpmvpM9\n",
            "To: /content/CitationSimilarityVectors106Epochs.npy\n",
            "2.59GB [00:29, 87.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-23aNm7j0bnycvyd_OaQfofVYPTewgOI\n",
            "To: /content/AbstractSimVectors.npy\n",
            "2.59GB [00:44, 58.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NyUQwgUNj9bFsiCnZ2TfKmWn5r-Y6wav\n",
            "To: /content/TitlesIdsAbstractsEmbedIdsCOMPLETE_12-30-19.json.gzip\n",
            "432MB [00:05, 79.5MB/s]\n",
            "--2020-01-06 04:58:56--  https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar\n",
            "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.200.160\n",
            "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.200.160|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 442460160 (422M) [application/x-tar]\n",
            "Saving to: ‘scibert_scivocab_uncased.tar’\n",
            "\n",
            "scibert_scivocab_un 100%[===================>] 421.96M  54.9MB/s    in 7.9s    \n",
            "\n",
            "2020-01-06 04:59:04 (53.8 MB/s) - ‘scibert_scivocab_uncased.tar’ saved [442460160/442460160]\n",
            "\n",
            "scibert_scivocab_uncased/\n",
            "scibert_scivocab_uncased/vocab.txt\n",
            "scibert_scivocab_uncased/pytorch_model.bin\n",
            "scibert_scivocab_uncased/config.json\n",
            "\u001b[K     |████████████████████████████████| 450kB 3.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 54.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 870kB 46.0MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "TensorFlow 2.x selected.\n",
            "TensorFlow: 2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvCrsHUhMXz4",
        "colab_type": "text"
      },
      "source": [
        "Install import tpu-index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtPyqrgLhHRw",
        "colab_type": "code",
        "outputId": "ac5d0321-1fd3-4f32-b6fd-445243bf3663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tpu-index\n",
        "from tpu_index import TPUIndex\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tpu-index\n",
            "  Downloading https://files.pythonhosted.org/packages/38/6a/c6739fb5a531683cc58fc2149d80f5a5e25997e085f312664fbbc7abd443/tpu_index-0.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow>=2.0.0 in /tensorflow-2.1.0/python3.6 (from tpu-index) (2.1.0rc1)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (2.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (3.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (1.17.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (2.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (1.11.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (0.1.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (3.11.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (1.13.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /tensorflow-2.1.0/python3.6 (from tensorflow>=2.0.0->tpu-index) (1.25.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (42.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (2.22.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (3.1.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (1.9.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (0.4.1)\n",
            "Requirement already satisfied: h5py in /tensorflow-2.1.0/python3.6 (from keras-applications>=1.0.8->tensorflow>=2.0.0->tpu-index) (2.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (1.25.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (3.0.4)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (0.2.7)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /tensorflow-2.1.0/python3.6 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /tensorflow-2.1.0/python3.6 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /tensorflow-2.1.0/python3.6 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.0.0->tpu-index) (3.1.0)\n",
            "Installing collected packages: tpu-index\n",
            "Successfully installed tpu-index-0.0.4\n",
            "WARNING:tensorflow:TPU system 10.74.47.146:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system 10.74.47.146:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.74.47.146:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.74.47.146:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnQredckMbZs",
        "colab_type": "text"
      },
      "source": [
        "# Set up TPU-Index for the citation similarity vectors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N039BRrahVn3",
        "colab_type": "code",
        "outputId": "e564e56f-a9d2-42d3-8eec-0f120b98ef9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "citations_embeddings = np.load('CitationSimilarityVectors106Epochs.npy')\n",
        "indexC = TPUIndex(num_tpu_cores=8)\n",
        "indexC.create_index(citations_embeddings.copy())\n",
        "del citations_embeddings\n",
        "print('System Memory used    : ' + str(psutil.virtual_memory().percent) + '%')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:0\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:1\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:2\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:3\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:4\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:5\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:6\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:7\n",
            "System Memory used    : 13.9%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1d9ubOuMlPc",
        "colab_type": "text"
      },
      "source": [
        "# Set up TPU-Index for the abstract similarity vectors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKdl1NybkU61",
        "colab_type": "code",
        "outputId": "7159d679-245f-41e5-da08-89c363dc44ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "abstract_embeddings = np.load('AbstractSimVectors.npy')\n",
        "indexA = TPUIndex(num_tpu_cores=8)\n",
        "indexA.create_index(abstract_embeddings.copy())\n",
        "del abstract_embeddings\n",
        "print('System Memory used    : ' + str(psutil.virtual_memory().percent) + '%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:0\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:1\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:2\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:3\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:4\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:5\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:6\n",
            "Building index with 157874 vectors on /job:worker/replica:0/task:0/device:TPU:7\n",
            "System Memory used    : 18.2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HesbpPrrMnl0",
        "colab_type": "text"
      },
      "source": [
        "Load model, tokenizer, and get semantic scholar papers data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syc0k8Yi4rcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.saved_model.load('gs://tfworld/saved_models')\n",
        "tokenizer = BertTokenizer(vocab_file='scibert_scivocab_uncased/vocab.txt')\n",
        "\n",
        "df = pd.read_json('/content/TitlesIdsAbstractsEmbedIdsCOMPLETE_12-30-19.json.gzip', compression = 'gzip')\n",
        "embed2Title = pd.Series(df['title'].values,index=df['EmbeddingID']).to_dict()\n",
        "embed2Abstract = pd.Series(df['paperAbstract'].values,index=df['EmbeddingID']).to_dict()\n",
        "embed2Paper = pd.Series(df['id'].values,index=df['EmbeddingID']).to_dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Vsv1L_Oq3t",
        "colab_type": "text"
      },
      "source": [
        "Inference. Type in your query, and get results. \n",
        "\n",
        "### NOTE: The first search will take about 40 seconds for the TPU to warm up. Each subsequent search should only take 100-150 ms. \n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFopFGOqit5y",
        "colab_type": "code",
        "outputId": "7a9d961c-2daa-4170-dfe8-fcbe432c4078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "query = \"neural machine translation\" #@param {type:\"string\"}\n",
        "\n",
        "Num_Results_Per_search = 10 #@param {type:\"integer\"}\n",
        "\n",
        "query_encoded = tokenizer.encode(query, max_length=512, pad_to_max_length=True)\n",
        "query_encoded = tf.constant(query_encoded, dtype=tf.int32)[None, :]\n",
        "print('\\nAbstract : ')\n",
        "pprint(query)\n",
        "\n",
        "s = time()\n",
        "bert_output = model(query_encoded)\n",
        "xq = tf.nn.l2_normalize(bert_output, axis=1)\n",
        "prediction_time = time() - s\n",
        "\n",
        "aD, aI = indexA.search(xq, distance_metric='cosine', top_k=Num_Results_Per_search)\n",
        "cD, cI = indexC.search(xq, distance_metric='cosine', top_k=Num_Results_Per_search)\n",
        "\n",
        "print('Abstract Embedding Search')\n",
        "print('*'*80)\n",
        "for i in range(len(aI)):\n",
        "    print('Title : ')\n",
        "    pprint(embed2Title[aI[i]])\n",
        "    print('\\n')\n",
        "    print('Abstract : ')\n",
        "    pprint(embed2Abstract[aI[i]])\n",
        "    print('\\n')\n",
        "    pprint('Link: www.semanticscholar.org/paper/'+embed2Paper[aI[i]])\n",
        "    print('\\n'*2)\n",
        "    print('*'*80)\n",
        "    print('\\n')\n",
        "print('\\nNeighbours       :', aI )\n",
        "print('Distances        :', np.round(aD, 4))\n",
        "\n",
        "print('Citation Embedding Search')\n",
        "for i in range(len(cI)):\n",
        "    print('Title : ')\n",
        "    pprint(embed2Title[cI[i]])\n",
        "    print('\\n')\n",
        "    print('Abstract : ')\n",
        "    pprint(embed2Abstract[cI[i]])\n",
        "    print('\\n')\n",
        "    pprint('Link: www.semanticscholar.org/paper/'+embed2Paper[cI[i]])\n",
        "    print('\\n'*2)\n",
        "    print('*'*80 )\n",
        "    print('\\n')\n",
        "print('\\nNeighbours       :', cI )\n",
        "print('Distances        :', np.round(cD, 4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Abstract : \n",
            "'neural machine translation'\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:0\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:1\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:2\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:3\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:4\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:5\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:6\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:7\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:0\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:1\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:2\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:3\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:4\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:5\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:6\n",
            "Search running on /job:worker/replica:0/task:0/device:TPU:7\n",
            "Abstract Embedding Search\n",
            "********************************************************************************\n",
            "Title : \n",
            "'Machine Translation'\n",
            "\n",
            "\n",
            "Abstract : \n",
            "('This paper discusses machine translation with regards to its '\n",
            " 'development,accuracy,readability, classification,application,and existing '\n",
            " 'problems.At the same time,it has analyzed several viewpoints held by people '\n",
            " 'towards machine translation.')\n",
            "\n",
            "\n",
            "'Link: www.semanticscholar.org/paper/311b26f623a2c61f029a1f0fd62bd34531b47aec'\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "Title : \n",
            "'Joint Training for Neural Machine Translation'\n",
            "\n",
            "\n",
            "Abstract : \n",
            "('The emergence of neural machine translation (NMT) has revolutionized the '\n",
            " 'filed of machine translation. In the first section, we introduce the '\n",
            " 'fundamental of NMT models. Then we study the advantages of NMT over '\n",
            " 'traditional statistical machine translations (SMT), some of its existing '\n",
            " 'challenges and recent research efforts. Finally, we summarize our four works '\n",
            " 'that address several existing problems in NMT. In the second section, we '\n",
            " 'follow attentional neural machine translation to use mathematical formula to '\n",
            " 'define the overall procedure for NMT.')\n",
            "\n",
            "\n",
            "'Link: www.semanticscholar.org/paper/6798b1c6e0b208f3e3f567e5e6172ffd0f6a52d7'\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "Title : \n",
            "'One decade of statistical machine translation: 1996-2005'\n",
            "\n",
            "\n",
            "Abstract : \n",
            "('In the last decade, the statistical approach has found widespread use in '\n",
            " 'machine translation both for written and spoken language and has had a major '\n",
            " 'impact on the translation accuracy. The goal of this paper is to cover the '\n",
            " 'state of the art in statistical machine translation. We would re-visit the '\n",
            " 'underlying principles of the statistical approach to machine translation and '\n",
            " 'summarize the progress that has been made over the last decade')\n",
            "\n",
            "\n",
            "'Link: www.semanticscholar.org/paper/06c2f8e67421b1bce89d6872148bf8a4c6943368'\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "Title : \n",
            "'Post-editing neural machine translation versus translation memory segments'\n",
            "\n",
            "\n",
            "Abstract : \n",
            "('The use of neural machine translation (NMT) in a professional scenario '\n",
            " 'implies a number of challenges despite growing evidence that, in language '\n",
            " 'combinations such as English to Spanish, NMT output quality has already '\n",
            " 'outperformed statistical machine translation in terms of automatic metric '\n",
            " 'scores. This article presents the result of an empirical test that aims to '\n",
            " 'shed light on the differences between NMT post-editing and translation with '\n",
            " 'the aid of a translation memory (TM). The results show that NMT post-editing '\n",
            " 'involves less editing than TM segments, but this editing appears to take '\n",
            " 'more time, with the consequence that NMT post-editing does not seem to '\n",
            " 'improve productivity as may have been expected. This might be due to the '\n",
            " 'fact that NMT segments show a higher variability in terms of quality and '\n",
            " 'time invested in post-editing than TM segments that are ‘more similar’ on '\n",
            " 'average. Finally, results show that translators who perceive that NMT boosts '\n",
            " 'their productivity actually performed faster than those who perceive that '\n",
            " 'NMT slows them down.')\n",
            "\n",
            "\n",
            "'Link: www.semanticscholar.org/paper/92cbb1590f1568b328c68ad9e8625029ea7ccdcc'\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "Title : \n",
            "('Neighbors helping the poor: improving low-resource machine translation using '\n",
            " 'related languages')\n",
            "\n",
            "\n",
            "Abstract : \n",
            "('Sentence-level parallel data is essential for training machine translation '\n",
            " 'systems. However, existing parallel data is extremely limited for thousands '\n",
            " 'of languages. In order to increase the available parallel data for a '\n",
            " 'low-resource language we borrow parallel data from a higher-resource closely '\n",
            " 'related language (RL). In so doing we propose a method for translating texts '\n",
            " 'from RL to the low-resource language without requiring any parallel data '\n",
            " 'between them. We use this method to convert RL/English parallel data and use '\n",
            " 'it as an extra resource for machine translation. We show that this extra '\n",
            " 'parallel data highly helps the BLEU score.')\n",
            "\n",
            "\n",
            "'Link: www.semanticscholar.org/paper/d0465fe6230dfba48f0d05a189da35fffbc48faf'\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Neighbours       : [542103 266804 901541 148399 747599]\n",
            "Distances        : [0.4161 0.4625 0.5222 0.525  0.5315]\n",
            "Citation Embedding Search\n",
            "Title : \n",
            "'Traffic incident detection algorithm based on non-parameter regression'\n",
            "\n",
            "\n",
            "Abstract : \n",
            "('We first describe the traffic congestion problem that many countries are '\n",
            " 'facing with in the world. Then we propose a traffic incident detection '\n",
            " 'algorithm based on non-parametric regression to solve the congestion '\n",
            " 'problem. Finally, we compare the algorithm with other incident detection '\n",
            " 'algorithms on the detection rate, false alarm rate and mean detection time. '\n",
            " 'A simulation result shows the algorithm proposed has higher detection rate, '\n",
            " 'lower false alarm rate and longer mean time detection. Furthermore, we state '\n",
            " 'the direction of our next study.')\n",
            "\n",
            "\n",
            "'Link: www.semanticscholar.org/paper/f6ddaf3fa9ff849ec863705aa2ddeec246366112'\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "Title : \n",
            "('Feedback Effects in Plasmonic Slot Waveguides Examined Using a Closed Form '\n",
            " 'Model')\n",
            "\n",
            "\n",
            "Abstract : \n",
            "('Analysis of the feedback effects in plasmonic waveguides is carried out '\n",
            " 'using an analytical model. The closed-form model is extracted from the '\n",
            " 'waveguide physical parameters is simple, accurate, and provides insight into '\n",
            " 'understanding the feedback effects in plasmonic waveguide structures. These '\n",
            " 'feedback effects are utilized to obtain various filter functions using the '\n",
            " 'same base structures, with exceptional tolerance to fabrication '\n",
            " 'imperfections in comparison to its plasmonic and dielectric counterparts.')\n",
            "\n",
            "\n",
            "'Link: www.semanticscholar.org/paper/219190aa8b7690ad6524e15b1617f4eedf389de0'\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "Title : \n",
            "'The gait identification challenge problem: data sets and baseline algorithm'\n",
            "\n",
            "\n",
            "Abstract : \n",
            "('Recognition of people through gait analysis is an important research topic, '\n",
            " 'with potential applications in video surveillance, tracking, and monitoring. '\n",
            " 'Recognizing the importance of evaluating and comparing possible competing '\n",
            " 'solutions to this problem, we previously introduced the HumanID challenge '\n",
            " 'problem consisting of a set of experiments of increasing difficulty, a '\n",
            " 'baseline algorithm, and a large set of video sequences (about 300 GB of data '\n",
            " 'related to 452 sequences from 74 subjects) acquired to investigate important '\n",
            " 'dimensions to this problem, such as variations due to viewpoint, footwear '\n",
            " 'and walking surface. In this paper we present a detailed investigation of '\n",
            " 'the baseline algorithm, quantify the dependence of the various covariates on '\n",
            " 'gait-based identification, and update the previous baseline performance with '\n",
            " 'optimized ones. We establish that the performance of the baseline algorithm '\n",
            " 'is robust with respect to its various parameters. The overall identification '\n",
            " 'performance is also stable with respect to the quality of the silhouettes. '\n",
            " 'We find that the approximately lower 20% of the silhouette accounts for most '\n",
            " 'of the recognition achieved. Viewpoint has barely statistically significant '\n",
            " 'effect on identification rates, whereas footwear and surface-type does have '\n",
            " 'significant effects with the effect due to surface-type being approximately '\n",
            " '5 times that of shoe-type.')\n",
            "\n",
            "\n",
            "'Link: www.semanticscholar.org/paper/06637fecb6cd2b600137451f8ea817c6c1f3a5be'\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "Title : \n",
            "('Effect of cryogenic deformation on the structure and properties of '\n",
            " 'chromium-nickel steels')\n",
            "\n",
            "\n",
            "Abstract : \n",
            "('The effect of rolling at a temperature of 77 K and subsequent tempering on '\n",
            " 'the structure and properties of chromium-nickel 05Kh14N14T2 and 15Kh14N14Yu1 '\n",
            " 'steels is investigated. The formation of a nanocrystalline martensite phase '\n",
            " 'in an austenitic matrix has been established. It is shown that additional '\n",
            " 'hardening of the metal occurs due to the precipitation of intermetallic '\n",
            " 'phases during heat treatment. The steels under study are high-strength and '\n",
            " 'hard-magnetic after cryogenic deformation and heat treatment.')\n",
            "\n",
            "\n",
            "'Link: www.semanticscholar.org/paper/c68d5fabaf75237abc88d32f0cadcfc4b21ab852'\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "Title : \n",
            "('A 30 V/1 MHz AC/AC converter for high frequency AC distributed power system '\n",
            " 'applications')\n",
            "\n",
            "\n",
            "Abstract : \n",
            "('This paper presents the design considerations for an AC/AC converter for '\n",
            " 'high frequency AC distributed power system (DPS) applications. The developed '\n",
            " 'circuit features simple structure and control strategy, high efficiency with '\n",
            " 'sine wave output. A low power loss startup circuit for two stage converter '\n",
            " 'is also proposed. Experimental results from a 200 VA 30 VAC/1 MHz converter '\n",
            " 'with efficiency of 90% confirm the validity of the theoretical analysis.')\n",
            "\n",
            "\n",
            "'Link: www.semanticscholar.org/paper/6d6a7eb62299c12e400357332bcd2b22dd084bdd'\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Neighbours       : [  96818   25686  438411  111103 1159377]\n",
            "Distances        : [0.6922 0.6964 0.6999 0.7057 0.7072]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}