{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "build_index_and_search_gpu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8wAw2JV6F4Am",
        "outputId": "56703d09-e050-43c6-bd33-2424fe644f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "!gdown --id \"10LV9QbZOkUyOzR4nh8hxesoKJhpmvpM9\"   # citation vectors\n",
        "!gdown --id \"1-23aNm7j0bnycvyd_OaQfofVYPTewgOI\"   # abstract vectors\n",
        "!gdown --id \"1NyUQwgUNj9bFsiCnZ2TfKmWn5r-Y6wav\"   # TitlesIdAbstractsEmbedIds\n",
        "!wget 'https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar'\n",
        "!tar -xvf 'scibert_scivocab_uncased.tar'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10LV9QbZOkUyOzR4nh8hxesoKJhpmvpM9\n",
            "To: /content/CitationSimilarityVectors106Epochs.npy\n",
            "2.59GB [00:40, 63.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-23aNm7j0bnycvyd_OaQfofVYPTewgOI\n",
            "To: /content/AbstractSimVectors.npy\n",
            "2.59GB [01:01, 42.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NyUQwgUNj9bFsiCnZ2TfKmWn5r-Y6wav\n",
            "To: /content/TitlesIdsAbstractsEmbedIdsCOMPLETE_12-30-19.json.gzip\n",
            "432MB [00:06, 68.7MB/s]\n",
            "--2019-12-30 23:29:18--  https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar\n",
            "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.252.32\n",
            "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.252.32|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 442460160 (422M) [application/x-tar]\n",
            "Saving to: ‘scibert_scivocab_uncased.tar’\n",
            "\n",
            "scibert_scivocab_un 100%[===================>] 421.96M  35.5MB/s    in 12s     \n",
            "\n",
            "2019-12-30 23:29:31 (33.8 MB/s) - ‘scibert_scivocab_uncased.tar’ saved [442460160/442460160]\n",
            "\n",
            "scibert_scivocab_uncased/\n",
            "scibert_scivocab_uncased/vocab.txt\n",
            "scibert_scivocab_uncased/pytorch_model.bin\n",
            "scibert_scivocab_uncased/config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP2AqdEiQhbS",
        "colab_type": "code",
        "outputId": "d60b4607-f1fe-4ff0-f5e1-1f7f6656d04b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install transformers --quiet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 450kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 860kB 62.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 52.9MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SGov6e8uGO3B",
        "outputId": "30983c8e-7ee6-44b0-b87a-4ce9fec83bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "print('TensorFlow:', tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "TensorFlow: 2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw_w81fx0fTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ca62452-c493-41be-9590-5e873ed698de"
      },
      "source": [
        "tf.config.experimental.list_physical_devices('GPU')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iht3WQa3H_g6",
        "outputId": "4fab6b5b-ae88-4905-d2bc-b42562071b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "REPLICAS:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ks95sxuIKbR",
        "outputId": "17e4f70f-0b1a-4c85-8dd0-83fbed607908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "workers = ['/GPU:0']\n",
        "workers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uByeXRrVO78_",
        "colab": {}
      },
      "source": [
        "class Index:\n",
        "    def __init__(self, embeddings, worker):\n",
        "        self.embeddings = tf.math.l2_normalize(embeddings, axis=1)\n",
        "        self.worker = worker\n",
        "\n",
        "    @tf.function\n",
        "    def search(self, query_vector):\n",
        "      with tf.device(worker):\n",
        "        dot_product = tf.reduce_sum(tf.multiply(self.embeddings, query_vector), axis=1)\n",
        "        distances = 1 - dot_product\n",
        "        sorted_indices =  tf.argsort(distances)\n",
        "        nearest_distances = tf.gather(distances, sorted_indices)\n",
        "        return nearest_distances[:20], sorted_indices[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DFloyWt7G8ts",
        "colab": {}
      },
      "source": [
        "citations_embeddings = np.load('CitationSimilarityVectors106Epochs.npy')\n",
        "abstract_embeddings = np.load('AbstractSimVectors.npy')\n",
        "assert citations_embeddings.shape == abstract_embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AB8L4sA-H2nf",
        "outputId": "0607ff66-e5f1-4657-dbbc-3187e402caf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vecs_per_index = citations_embeddings.shape[0]\n",
        "print('Vectors per index :', vecs_per_index)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectors per index : 1262996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HoEA0SqeJW4n",
        "outputId": "4a34722b-78e6-49ec-de08-a54f206cee2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Place 1/8 of total embeddings on each TPU core\n",
        "citation_indices = []\n",
        "abstract_indices = []\n",
        "for i, worker in enumerate(workers):\n",
        "  with tf.device(worker):\n",
        "    print('Building index with {} vectors on {}'.format(citations_embeddings.shape[0], worker))\n",
        "    citation_indices.append(Index(citations_embeddings, worker))\n",
        "    abstract_indices.append(Index(abstract_embeddings, worker))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building index with 1262996 vectors on /GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W5r4LmcVqGAZ",
        "colab": {}
      },
      "source": [
        "def search(xq, top_k=10):\n",
        "  cD, cI = [], []\n",
        "  aD, aI = [], []\n",
        "  for i in range(1):\n",
        "    print('Search running on {}'.format(citation_indices[i].worker))\n",
        "    cd, cidx = citation_indices[i].search(xq)\n",
        "    ad, aidx = abstract_indices[i].search(xq)\n",
        "\n",
        "    cD.extend(cd.numpy())\n",
        "    aD.extend(ad.numpy())\n",
        "\n",
        "    cI.extend(i*vecs_per_index + cidx.numpy())\n",
        "    aI.extend(i*vecs_per_index + aidx.numpy())\n",
        "\n",
        "  cid_sorted = np.argsort(cD)[:top_k]\n",
        "  aid_sorted = np.argsort(aD)[:top_k]\n",
        "\n",
        "  cD = np.array(cD)[cid_sorted]\n",
        "  aD = np.array(aD)[aid_sorted]\n",
        "\n",
        "  cI = np.array(cI)[cid_sorted]\n",
        "  aI = np.array(aI)[aid_sorted]\n",
        "  return cD, aD, cI, aI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syc0k8Yi4rcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.saved_model.load('gs://tfworld/saved_models')\n",
        "tokenizer = BertTokenizer(vocab_file='scibert_scivocab_uncased/vocab.txt')\n",
        "\n",
        "df = pd.read_json('/content/TitlesIdsAbstractsEmbedIdsCOMPLETE_12-30-19.json.gzip', compression = 'gzip')\n",
        "embed2Title = pd.Series(df['title'].values,index=df['EmbeddingID']).to_dict()\n",
        "embed2Abstract = pd.Series(df['paperAbstract'].values,index=df['EmbeddingID']).to_dict()\n",
        "embed2Paper = pd.Series(df['id'].values,index=df['EmbeddingID']).to_dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxkcuP0CDNKM",
        "colab_type": "code",
        "outputId": "0e859545-10a9-46e4-88f3-eaa0eff60562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# embed_id = 70\n",
        "title ='Money' #embed2Title[embed_id]\n",
        "# abstract = embed2Abstract[embed_id]\n",
        "abstract = '''Financial modelling for assets'''\n",
        "\n",
        "abstract_encoded = tokenizer.encode(abstract, max_length=512, pad_to_max_length=True)\n",
        "abstract_encoded = tf.constant(abstract_encoded, dtype=tf.int32)[None, :]\n",
        "print('Title : ')\n",
        "pprint(title)\n",
        "print('\\nAbstract : ')\n",
        "pprint(abstract)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title : \n",
            "'Money'\n",
            "\n",
            "Abstract : \n",
            "'Financial modelling for assets'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhiyvUxrF4xr",
        "colab_type": "code",
        "outputId": "bd918168-95c4-4402-bd39-ea2870ab2270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "s = time()\n",
        "bert_output = model(abstract_encoded)\n",
        "xq = tf.nn.l2_normalize(bert_output, axis=1)\n",
        "e_p = time()\n",
        "\n",
        "cD, aD, cI, aI = search(xq, top_k=5)\n",
        "e_s = time()\n",
        "print('\\n'*2)\n",
        "print('Prediction time  :', np.round(e_p-s, 3), 'secs')\n",
        "print('Search time      :', np.round(e_s-e_p, 3), 'secs')\n",
        "print('Total time       :', np.round(e_s - s, 3), 'secs')\n",
        "\n",
        "print('\\n'*2)\n",
        "print('*'*80)\n",
        "for i in range(len(cI)):\n",
        "  print('Title : ')\n",
        "  pprint(embed2Title[cI[i]])\n",
        "  print('\\n')\n",
        "  pprint('Link: semanticscholar.org/paper/'+embed2Paper[cI[i]])\n",
        "  print('*'*80, )\n",
        "print('\\nNeighbours       :', cI )\n",
        "print('Distances        :', np.round(cD, 4))\n",
        "\n",
        "print('\\n'*4)\n",
        "print('*'*80)\n",
        "for i in range(len(aI)):\n",
        "  print('Abstract : ')\n",
        "  pprint(embed2Abstract[aI[i]])\n",
        "  print('\\n')\n",
        "  pprint('Link: semanticscholar.org/paper/'+embed2Paper[aI[i]])\n",
        "  print('*'*80)\n",
        "print('\\nNeighbours       :', aI )\n",
        "print('Distances        :', np.round(aD, 4))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search running on /GPU:0\n",
            "\n",
            "\n",
            "\n",
            "Prediction time  : 0.048 secs\n",
            "Search time      : 0.066 secs\n",
            "Total time       : 0.114 secs\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "Title : \n",
            "('Approach for improving receiver performance in loss-free handovers in DVB-H '\n",
            " 'networks')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/85fabe4a29a5eea59d78e3e5005c43837ad61837'\n",
            "********************************************************************************\n",
            "Title : \n",
            "'Qualification of the Joints for the ITER Central Solenoid'\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/b2c88eb44c152fb189edf2113466621a2d54dcee'\n",
            "********************************************************************************\n",
            "Title : \n",
            "('Solar energy as alternative power supply for communication system IEEE '\n",
            " '802.15.4 standard')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/dcb499aefe2182be7f25033579f0bf17ef8bf20c'\n",
            "********************************************************************************\n",
            "Title : \n",
            "('Combinatorial invariance of Kazhdan–Lusztig–Vogan polynomials for fixed '\n",
            " 'point free involutions')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/1ab584117236609cb06e26a5e01103e43d803530'\n",
            "********************************************************************************\n",
            "Title : \n",
            "'The Bruhat order on clans'\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/443dcc67cee280fe937617accdf59197ff5d3c1d'\n",
            "********************************************************************************\n",
            "\n",
            "Neighbours       : [  28327  873572  629316  927389 1035631]\n",
            "Distances        : [0.6475 0.6699 0.6778 0.6818 0.6822]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('In this study we are trying with the neural network model to make an '\n",
            " 'effective analysis for corporation credit rating. A 12-25-1 three-layer '\n",
            " 'feedforward neural network using the backpropagation and Levenberg-Marquardt '\n",
            " 'algorithms has been used in the proposed artificial neural network. The '\n",
            " 'experiment results show that this network is efficient and forms a useful '\n",
            " 'tool for the prediction of corporation credit rating.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/732656b397bc93e3fcb7a85087e376a781524b46'\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('This paper explores the effects of a firm’s cash flow systematic risk on its '\n",
            " 'optimal capital structure. In a model where firms are allowed to borrow '\n",
            " 'resources from a competitive lending sector, those with cash flows more '\n",
            " 'correlated with the aggregate economy (i.e., firms with riskier assets in '\n",
            " 'place) choose a lower leverage given their higher expected financing costs. '\n",
            " 'On the other hand, less risky firms, having lower expected financing costs, '\n",
            " 'optimally choose to issue more debt to exploit a tax advantage. The model '\n",
            " 'predicts that cash flow systematic risk is negatively correlated with '\n",
            " 'leverage and corporate bond yields.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/56b9d3a8b6d5a850b0e37ad0c3695e884c7d5e46'\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('In this paper, we propose a robust and novel ensemble model for Net asset '\n",
            " 'value prediction of Mutual fund. The proposed model is constituted of two '\n",
            " 'non-linear models: Radial basis function (RBF) and Functional link '\n",
            " 'artificial neural network (FLANN). In order to improve the prediction '\n",
            " 'performance of the hybrid model a boosting technique is used. The sum of the '\n",
            " 'weighted outputs of the two models is compared with the target values to '\n",
            " 'minimize the mean square error. The proposed model shows improved '\n",
            " 'performance in terms of MAPE and RMSE values in comparison to each '\n",
            " 'individual model.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/39ba7a59ce220ee247b97d4759cf5eee3d7261b5'\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('We discuss extensions of reduced-form and structural models for pricing '\n",
            " 'credit risky securities to portfolio simulation and valuation. Stochasticity '\n",
            " 'in interest rates and credit spreads is captured via reduced-form models and '\n",
            " 'is incorporated with a default and migration model based on the structural '\n",
            " 'credit risk modelling approach. Calculated prices are consistent with '\n",
            " 'observed prices and the term structure of default-free and defaultable '\n",
            " 'interest rates. Three applications are discussed: (i) study of the '\n",
            " 'inter-temporal price sensitivity of credit bonds and the sensitivity of '\n",
            " 'future portfolio valuation with respect to changes in interest rates, '\n",
            " 'default probabilities, recovery rates and rating migration, (ii) study of '\n",
            " 'the structure of credit risk by investigating the impact of disparate risk '\n",
            " 'factors on portfolio risk, and (iii) tracking of corporate bond indices via '\n",
            " 'simulation and optimisation models. In particular, we study the effect of '\n",
            " 'uncertainty in credit spreads and interest rates on the overall risk of a '\n",
            " 'credit portfolio, a topic that has been recently discussed by Kiesel et al. '\n",
            " '[The structure of credit risk: spread volatility and ratings transitions. '\n",
            " 'Technical report, Bank of England, ISSN 1268-5562, 2001], but has been '\n",
            " 'otherwise mostly neglected. We find that spread risk and interest rate risk '\n",
            " 'are important factors that do not diversify away in a large portfolio '\n",
            " 'context, especially when high-quality instruments are considered.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/17ef2645e2928e73b1a75172c702d098e5cc380e'\n",
            "********************************************************************************\n",
            "Abstract : \n",
            "('Illiquidity and market impact refer to the situation where it may be costly '\n",
            " 'or difficult to trade a desired quantity of assets over a desire period of '\n",
            " 'time. In this paper, we formulate a simple model of dynamic portfolio choice '\n",
            " 'that incorporates liquidity effects. The resulting problem is a stochastic '\n",
            " 'linear quadratic control problem where liquidity costs are modeled as a '\n",
            " 'quadratic penalty on the trading rate. Though easily computable via Riccati '\n",
            " 'equations, we also derive a multiple time scale asymptotic expansion of the '\n",
            " 'value function and optimal trading rate in the regime of vanishing market '\n",
            " 'impact costs. This expansion reveals an interesting but intuitive '\n",
            " 'relationship between the optimal trading rate for the “illiquid” problem and '\n",
            " 'the classical Merton model for dynamic portfolio selection in perfectly '\n",
            " 'liquid markets. It also gives rise to the notion of a “liquidity time scale” '\n",
            " 'which shows how trading horizon and market impact costs affect the optimal '\n",
            " 'trading rate.')\n",
            "\n",
            "\n",
            "'Link: semanticscholar.org/paper/72ad391a6344d8cf6b4242c5867a11a2b811ff1a'\n",
            "********************************************************************************\n",
            "\n",
            "Neighbours       : [371932 835910 965602 150355 148662]\n",
            "Distances        : [0.5284 0.5302 0.5309 0.5345 0.5452]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nv5KmtIJK0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}